Id,Category,Title,Published,Abstract,URL,Author
2308.15930v1,cs.CL,LLaSM: Large Language and Speech Model,2023-08-30 10:12:39+00:00,"Multi-modal large language models have garnered significant interest
recently. Though, most of the works focus on vision-language multi-modal models
providing strong capabilities in following vision-and-language instructions.
However, we claim that speech is also an important modality through which
humans interact with the world. Hence, it is crucial for a general-purpose
assistant to be able to follow multi-modal speech-and-language instructions. In
this work, we propose Large Language and Speech Model (LLaSM). LLaSM is an
end-to-end trained large multi-modal speech-language model with cross-modal
conversational abilities, capable of following speech-and-language
instructions. Our early experiments show that LLaSM demonstrates a more
convenient and natural way for humans to interact with artificial intelligence.
Specifically, we also release a large Speech Instruction Following dataset
LLaSM-Audio-Instructions. Code and demo are available at
https://github.com/LinkSoul-AI/LLaSM and
https://huggingface.co/spaces/LinkSoul/LLaSM. The LLaSM-Audio-Instructions
dataset is available at
https://huggingface.co/datasets/LinkSoul/LLaSM-Audio-Instructions.",http://arxiv.org/pdf/2308.15930v1,"[arxiv.Result.Author('Yu Shu'), arxiv.Result.Author('Siwei Dong'), arxiv.Result.Author('Guangyao Chen'), arxiv.Result.Author('Wenhao Huang'), arxiv.Result.Author('Ruihua Zhang'), arxiv.Result.Author('Daochen Shi'), arxiv.Result.Author('Qiqi Xiang'), arxiv.Result.Author('Yemin Shi')]"
2308.15962v1,cs.RO,WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model,2023-08-30 11:35:21+00:00,"Enabling robots to understand language instructions and react accordingly to
visual perception has been a long-standing goal in the robotics research
community. Achieving this goal requires cutting-edge advances in natural
language processing, computer vision, and robotics engineering. Thus, this
paper mainly investigates the potential of integrating the most recent Large
Language Models (LLMs) and existing visual grounding and robotic grasping
system to enhance the effectiveness of the human-robot interaction. We
introduce the WALL-E (Embodied Robotic WAiter load lifting with Large Language
model) as an example of this integration. The system utilizes the LLM of
ChatGPT to summarize the preference object of the users as a target instruction
via the multi-round interactive dialogue. The target instruction is then
forwarded to a visual grounding system for object pose and size estimation,
following which the robot grasps the object accordingly. We deploy this
LLM-empowered system on the physical robot to provide a more user-friendly
interface for the instruction-guided grasping task. The further experimental
results on various real-world scenarios demonstrated the feasibility and
efficacy of our proposed framework.",http://arxiv.org/pdf/2308.15962v1,"[arxiv.Result.Author('Tianyu Wang'), arxiv.Result.Author('Yifan Li'), arxiv.Result.Author('Haitao Lin'), arxiv.Result.Author('Xiangyang Xue'), arxiv.Result.Author('Yanwei Fu')]"
2308.15812v1,cs.LG,Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models,2023-08-30 07:35:32+00:00,"Aligning large language models (LLMs) with human values and intents
critically involves the use of human or AI feedback. While dense feedback
annotations are expensive to acquire and integrate, sparse feedback presents a
structural design choice between ratings (e.g., score Response A on a scale of
1-7) and rankings (e.g., is Response A better than Response B?). In this work,
we analyze the effect of this design choice for the alignment and evaluation of
LLMs. We uncover an inconsistency problem wherein the preferences inferred from
ratings and rankings significantly disagree 60% for both human and AI
annotators. Our subsequent analysis identifies various facets of annotator
biases that explain this phenomena, such as human annotators would rate denser
responses higher while preferring accuracy during pairwise judgments. To our
surprise, we also observe that the choice of feedback protocol also has a
significant effect on the evaluation of aligned LLMs. In particular, we find
that LLMs that leverage rankings data for alignment (say model X) are preferred
over those that leverage ratings data (say model Y), with a rank-based
evaluation protocol (is X/Y's response better than reference response?) but not
with a rating-based evaluation protocol (score Rank X/Y's response on a scale
of 1-7). Our findings thus shed light on critical gaps in methods for
evaluating the real-world utility of language models and their strong
dependence on the feedback protocol used for alignment. Our code and data are
available at https://github.com/Hritikbansal/sparse_feedback.",http://arxiv.org/pdf/2308.15812v1,"[arxiv.Result.Author('Hritik Bansal'), arxiv.Result.Author('John Dang'), arxiv.Result.Author('Aditya Grover')]"
2308.15944v1,cs.SE,WUDI: A Human Involved Self-Adaptive Framework to Prevent Childhood Obesity in Internet of Things Environment,2023-08-30 10:52:00+00:00,"The Internet of Things (IoT) connects people, devices, and information
resources, in various domains to improve efficiency. The healthcare domain has
been transformed by the integration of the IoT, leading to the development of
digital healthcare solutions such as health monitoring, emergency detection,
and remote operation. This integration has led to an increase in the health
data collected from a variety of IoT sources. Consequently, advanced
technologies are required to analyze health data, and artificial intelligence
has been employed to extract meaningful insights from the data. Childhood
overweight and obesity have emerged as some of the most serious global public
health challenges, as they can lead to a variety of health-related problems and
the early development of chronic diseases. To address this, a self-adaptive
framework is proposed to prevent childhood obesity by using lifelog data from
IoT environments, with human involvement being an important consideration in
the framework. The framework uses an ensemble-based learning model to predict
obesity using the lifelog data. Empirical experiments using lifelog data from
smartphone applications were conducted to validate the effectiveness of human
involvement and obesity prediction. The results demonstrated the efficiency of
the proposed framework with human involvement in obesity prediction. The
proposed framework can be applied in real-world healthcare services for
childhood obesity.",http://arxiv.org/pdf/2308.15944v1,"[arxiv.Result.Author('Euijong Lee'), arxiv.Result.Author('Jaemin Jung'), arxiv.Result.Author('Gee-Myung Moon'), arxiv.Result.Author('Seong-Whan Lee'), arxiv.Result.Author('Ji-Hoon Jeong')]"
2308.16137v1,cs.CL,LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models,2023-08-30 16:47:51+00:00,"In recent years, there have been remarkable advancements in the performance
of Transformer-based Large Language Models (LLMs) across various domains. As
these LLMs are deployed for increasingly complex tasks, they often face the
needs to conduct longer reasoning processes or understanding larger contexts.
In these situations, the length generalization failure of LLMs on long
sequences become more prominent. Most pre-training schemes truncate training
sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to
generate fluent texts, let alone carry out downstream tasks, after longer
contexts, even with relative positional encoding which is designed to cope with
this problem. Common solutions such as finetuning on longer corpora often
involves daunting hardware and time costs and requires careful training process
design. To more efficiently leverage the generation capacity of existing LLMs,
we theoretically and empirically investigate the main out-of-distribution (OOD)
factors contributing to this problem. Inspired by this diagnosis, we propose a
simple yet effective solution for on-the-fly length generalization,
LM-Infinite, which involves only a $\Lambda$-shaped attention mask and a
distance limit while requiring no parameter updates or learning. We find it
applicable to a variety of LLMs using relative-position encoding methods.
LM-Infinite is computational efficient with $O(n)$ time and space, and
demonstrates consistent fluency and generation quality to as long as 32k tokens
on ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream
task such as passkey retrieval, it continues to work on inputs much longer than
training lengths where vanilla models fail immediately.",http://arxiv.org/pdf/2308.16137v1,"[arxiv.Result.Author('Chi Han'), arxiv.Result.Author('Qifan Wang'), arxiv.Result.Author('Wenhan Xiong'), arxiv.Result.Author('Yu Chen'), arxiv.Result.Author('Heng Ji'), arxiv.Result.Author('Sinong Wang')]"
