Id,Category,Title,Abstract,label
2212.09410v1,cs.CL,Less is More: Parameter-Free Text Classification with Gzip,"Deep neural networks (DNNs) are often used for text classification tasks as
they usually achieve high levels of accuracy. However, DNNs can be
computationally intensive with billions of parameters and large amounts of
labeled data, which can make them expensive to use, to optimize and to transfer
to out-of-distribution (OOD) cases in practice. In this paper, we propose a
non-parametric alternative to DNNs that's easy, light-weight and universal in
text classification: a combination of a simple compressor like gzip with a
$k$-nearest-neighbor classifier. Without any training, pre-training or
fine-tuning, our method achieves results that are competitive with
non-pretrained deep learning methods on six in-distributed datasets. It even
outperforms BERT on all five OOD datasets, including four low-resource
languages. Our method also performs particularly well in few-shot settings
where labeled data are too scarce for DNNs to achieve a satisfying accuracy.",10
1906.02506v2,stat.ML,Practical Deep Learning with Bayesian Principles,"Bayesian methods promise to fix many shortcomings of deep learning, but they
are impractical and rarely match the performance of standard methods, let alone
improve them. In this paper, we demonstrate practical training of deep networks
with natural-gradient variational inference. By applying techniques such as
batch normalisation, data augmentation, and distributed training, we achieve
similar performance in about the same number of epochs as the Adam optimiser,
even on large datasets such as ImageNet. Importantly, the benefits of Bayesian
principles are preserved: predictive probabilities are well-calibrated,
uncertainties on out-of-distribution data are improved, and continual-learning
performance is boosted. This work enables practical deep learning while
preserving benefits of Bayesian principles. A PyTorch implementation is
available as a plug-and-play optimiser.",10
1706.03762v7,cs.CL,Attention Is All You Need,"The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks in an encoder-decoder configuration. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer, based
solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to be
superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014
English-to-German translation task, improving over the existing best results,
including ensembles by over 2 BLEU. On the WMT 2014 English-to-French
translation task, our model establishes a new single-model state-of-the-art
BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction
of the training costs of the best models from the literature. We show that the
Transformer generalizes well to other tasks by applying it successfully to
English constituency parsing both with large and limited training data.",10
2307.10169v1,cs.CL,Challenges and Applications of Large Language Models,"Large Language Models (LLMs) went from non-existent to ubiquitous in the
machine learning discourse within a few years. Due to the fast pace of the
field, it is difficult to identify the remaining challenges and already
fruitful application areas. In this paper, we aim to establish a systematic set
of open problems and application successes so that ML researchers can
comprehend the field's current state more quickly and become productive.",10
2308.01320v1,cs.LG,"DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales","ChatGPT-like models have revolutionized various applications in artificial
intelligence, from summarization and coding to translation, matching or even
surpassing human performance. However, the current landscape lacks an
accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement
Learning with Human Feedback) training pipeline for these powerful models,
particularly when training at the scale of billions of parameters. This paper
introduces DeepSpeed-Chat, a novel system that democratizes RLHF training,
making it accessible to the AI community. DeepSpeed-Chat offers three key
capabilities: an easy-to-use training and inference experience for ChatGPT-like
models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from
InstructGPT, and a robust DeepSpeed-RLHF system that combines various
optimizations for training and inference in a unified way. The system delivers
unparalleled efficiency and scalability, enabling training of models with
hundreds of billions of parameters in record time and at a fraction of the
cost. With this development, DeepSpeed-Chat paves the way for broader access to
advanced RLHF training, even for data scientists with limited resources,
thereby fostering innovation and further development in the field of AI.",10
2005.14165v4,cs.CL,Language Models are Few-Shot Learners,"Recent work has demonstrated substantial gains on many NLP tasks and
benchmarks by pre-training on a large corpus of text followed by fine-tuning on
a specific task. While typically task-agnostic in architecture, this method
still requires task-specific fine-tuning datasets of thousands or tens of
thousands of examples. By contrast, humans can generally perform a new language
task from only a few examples or from simple instructions - something which
current NLP systems still largely struggle to do. Here we show that scaling up
language models greatly improves task-agnostic, few-shot performance, sometimes
even reaching competitiveness with prior state-of-the-art fine-tuning
approaches. Specifically, we train GPT-3, an autoregressive language model with
175 billion parameters, 10x more than any previous non-sparse language model,
and test its performance in the few-shot setting. For all tasks, GPT-3 is
applied without any gradient updates or fine-tuning, with tasks and few-shot
demonstrations specified purely via text interaction with the model. GPT-3
achieves strong performance on many NLP datasets, including translation,
question-answering, and cloze tasks, as well as several tasks that require
on-the-fly reasoning or domain adaptation, such as unscrambling words, using a
novel word in a sentence, or performing 3-digit arithmetic. At the same time,
we also identify some datasets where GPT-3's few-shot learning still struggles,
as well as some datasets where GPT-3 faces methodological issues related to
training on large web corpora. Finally, we find that GPT-3 can generate samples
of news articles which human evaluators have difficulty distinguishing from
articles written by humans. We discuss broader societal impacts of this finding
and of GPT-3 in general.",10
2106.09685v2,cs.CL,LoRA: Low-Rank Adaptation of Large Language Models,"An important paradigm of natural language processing consists of large-scale
pre-training on general domain data and adaptation to particular tasks or
domains. As we pre-train larger models, full fine-tuning, which retrains all
model parameters, becomes less feasible. Using GPT-3 175B as an example --
deploying independent instances of fine-tuned models, each with 175B
parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or
LoRA, which freezes the pre-trained model weights and injects trainable rank
decomposition matrices into each layer of the Transformer architecture, greatly
reducing the number of trainable parameters for downstream tasks. Compared to
GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable
parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA
performs on-par or better than fine-tuning in model quality on RoBERTa,
DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher
training throughput, and, unlike adapters, no additional inference latency. We
also provide an empirical investigation into rank-deficiency in language model
adaptation, which sheds light on the efficacy of LoRA. We release a package
that facilitates the integration of LoRA with PyTorch models and provide our
implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at
https://github.com/microsoft/LoRA.",10
2307.06324v4,math.OC,Provably Faster Gradient Descent via Long Steps,"This work establishes provably faster convergence rates for gradient descent
in smooth convex optimization via a computer-assisted analysis technique. Our
theory allows nonconstant stepsize policies with frequent long steps
potentially violating descent by analyzing the overall effect of many
iterations at once rather than the typical one-iteration inductions used in
most first-order method analyses. We show that long steps, which may increase
the objective value in the short term, lead to provably faster convergence in
the long term. A conjecture towards proving a faster $O(1/T\log T)$ rate for
gradient descent is also motivated along with simple numerical validation.",10
2308.00675v1,cs.CL,Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models,"Today, large language models (LLMs) are taught to use new tools by providing
a few demonstrations of the tool's usage. Unfortunately, demonstrations are
hard to acquire, and can result in undesirable biased usage if the wrong
demonstration is chosen. Even in the rare scenario that demonstrations are
readily available, there is no principled selection protocol to determine how
many and which ones to provide. As tasks grow more complex, the selection
search grows combinatorially and invariably becomes intractable. Our work
provides an alternative to demonstrations: tool documentation. We advocate the
use of tool documentation, descriptions for the individual tool usage, over
demonstrations. We substantiate our claim through three main empirical findings
on 6 tasks across both vision and language modalities. First, on existing
benchmarks, zero-shot prompts with only tool documentation are sufficient for
eliciting proper tool usage, achieving performance on par with few-shot
prompts. Second, on a newly collected realistic tool-use dataset with hundreds
of available tool APIs, we show that tool documentation is significantly more
valuable than demonstrations, with zero-shot documentation significantly
outperforming few-shot without documentation. Third, we highlight the benefits
of tool documentations by tackling image generation and video tracking using
just-released unseen state-of-the-art models as tools. Finally, we highlight
the possibility of using tool documentation to automatically enable new
applications: by using nothing more than the documentation of GroundingDino,
Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the
just-released Grounded-SAM and Track Anything models.",10
2308.12950v2,cs.CL,Code Llama: Open Foundation Models for Code,"We release Code Llama, a family of large language models for code based on
Llama 2 providing state-of-the-art performance among open models, infilling
capabilities, support for large input contexts, and zero-shot instruction
following ability for programming tasks. We provide multiple flavors to cover a
wide range of applications: foundation models (Code Llama), Python
specializations (Code Llama - Python), and instruction-following models (Code
Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained
on sequences of 16k tokens and show improvements on inputs with up to 100k
tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support
infilling based on surrounding content. Code Llama reaches state-of-the-art
performance among open models on several code benchmarks, with scores of up to
53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python
7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform
every other publicly available model on MultiPL-E. We release Code Llama under
a permissive license that allows for both research and commercial use.",10
2305.14965v1,cs.CL,"Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks","Recent explorations with commercial Large Language Models (LLMs) have shown
that non-expert users can jailbreak LLMs by simply manipulating the prompts;
resulting in degenerate output behavior, privacy and security breaches,
offensive outputs, and violations of content regulator policies. Limited formal
studies have been carried out to formalize and analyze these attacks and their
mitigations. We bridge this gap by proposing a formalism and a taxonomy of
known (and possible) jailbreaks. We perform a survey of existing jailbreak
methods and their effectiveness on open-source and commercial LLMs (such as GPT
3.5, OPT, BLOOM, and FLAN-T5-xxl). We further propose a limited set of prompt
guards and discuss their effectiveness against known attack types.",10
2301.02737v2,cs.SI,Understanding the (In)Effectiveness of Content Moderation: A Case Study of Facebook in the Context of the U.S. Capitol Riot,"Social media networks commonly employ content moderation as a tool to limit
the spread of harmful content. However, the efficacy of this strategy in
limiting the delivery of harmful content to users is not well understood. In
this paper, we create a framework to quantify the efficacy of content
moderation and use our metrics to analyze content removal on Facebook within
the U.S. news ecosystem. In a data set of over 2M posts with 1.6B user
engagements collected from 2,551 U.S. news sources before and during the
Capitol Riot on January 6, 2021, we identify 10,811 removed posts. We find that
the active engagement life cycle of Facebook posts is very short, with 90% of
all engagement occurring within the first 30 hours after posting. Thus, even
relatively quick intervention allowed significant accrual of engagement before
removal, and prevented only 21% of the predicted engagement potential during a
baseline period before the U.S. Capitol attack. Nearly a week after the attack,
Facebook began removing older content, but these removals occurred so late in
these posts' engagement life cycles that they disrupted less than 1% of
predicted future engagement, highlighting the limited impact of this
intervention. Content moderation likely has limits in its ability to prevent
engagement, especially in a crisis, and we recommend that other approaches such
as slowing down the rate of content diffusion be investigated.",8
2003.01207v1,cs.AI,BARD: A structured technique for group elicitation of Bayesian networks to support analytic reasoning,"In many complex, real-world situations, problem solving and decision making
require effective reasoning about causation and uncertainty. However, human
reasoning in these cases is prone to confusion and error. Bayesian networks
(BNs) are an artificial intelligence technology that models uncertain
situations, supporting probabilistic and causal reasoning and decision making.
However, to date, BN methodologies and software require significant upfront
training, do not provide much guidance on the model building process, and do
not support collaboratively building BNs. BARD (Bayesian ARgumentation via
Delphi) is both a methodology and an expert system that utilises (1) BNs as the
underlying structured representations for better argument analysis, (2) a
multi-user web-based software platform and Delphi-style social processes to
assist with collaboration, and (3) short, high-quality e-courses on demand, a
highly structured process to guide BN construction, and a variety of helpful
tools to assist in building and reasoning with BNs, including an automated
explanation tool to assist effective report writing. The result is an
end-to-end online platform, with associated online training, for groups without
prior BN expertise to understand and analyse a problem, build a model of its
underlying probabilistic causal structure, validate and reason with the causal
model, and use it to produce a written analytic report. Initial experimental
results demonstrate that BARD aids in problem solving, reasoning and
collaboration.",10
2204.02311v5,cs.CL,PaLM: Scaling Language Modeling with Pathways,"Large language models have been shown to achieve remarkable performance
across a variety of natural language tasks using few-shot learning, which
drastically reduces the number of task-specific training examples needed to
adapt the model to a particular application. To further our understanding of
the impact of scale on few-shot learning, we trained a 540-billion parameter,
densely activated, Transformer language model, which we call Pathways Language
Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML
system which enables highly efficient training across multiple TPU Pods. We
demonstrate continued benefits of scaling by achieving state-of-the-art
few-shot learning results on hundreds of language understanding and generation
benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough
performance, outperforming the finetuned state-of-the-art on a suite of
multi-step reasoning tasks, and outperforming average human performance on the
recently released BIG-bench benchmark. A significant number of BIG-bench tasks
showed discontinuous improvements from model scale, meaning that performance
steeply increased as we scaled to our largest model. PaLM also has strong
capabilities in multilingual tasks and source code generation, which we
demonstrate on a wide array of benchmarks. We additionally provide a
comprehensive analysis on bias and toxicity, and study the extent of training
data memorization with respect to model scale. Finally, we discuss the ethical
considerations related to large language models and discuss potential
mitigation strategies.",10
2307.12008v1,cond-mat.supr-con,The First Room-Temperature Ambient-Pressure Superconductor,"For the first time in the world, we succeeded in synthesizing the
room-temperature superconductor ($T_c \ge 400$ K, 127$^\circ$C) working at
ambient pressure with a modified lead-apatite (LK-99) structure. The
superconductivity of LK-99 is proved with the Critical temperature ($T_c$),
Zero-resistivity, Critical current ($I_c$), Critical magnetic field ($H_c$),
and the Meissner effect. The superconductivity of LK-99 originates from minute
structural distortion by a slight volume shrinkage (0.48 %), not by external
factors such as temperature and pressure. The shrinkage is caused by Cu$^{2+}$
substitution of Pb$^{2+}$(2) ions in the insulating network of Pb(2)-phosphate
and it generates the stress. It concurrently transfers to Pb(1) of the
cylindrical column resulting in distortion of the cylindrical column interface,
which creates superconducting quantum wells (SQWs) in the interface. The heat
capacity results indicated that the new model is suitable for explaining the
superconductivity of LK-99. The unique structure of LK-99 that allows the
minute distorted structure to be maintained in the interfaces is the most
important factor that LK-99 maintains and exhibits superconductivity at room
temperatures and ambient pressure.",10
2308.15122v1,cs.CL,SpikeBERT: A Language Spikformer Trained with Two-Stage Knowledge Distillation from BERT,"Spiking neural networks (SNNs) offer a promising avenue to implement deep
neural networks in a more energy-efficient way. However, the network
architectures of existing SNNs for language tasks are too simplistic, and deep
architectures have not been fully explored, resulting in a significant
performance gap compared to mainstream transformer-based networks such as BERT.
To this end, we improve a recently-proposed spiking transformer (i.e.,
Spikformer) to make it possible to process language tasks and propose a
two-stage knowledge distillation method for training it, which combines
pre-training by distilling knowledge from BERT with a large collection of
unlabelled texts and fine-tuning with task-specific instances via knowledge
distillation again from the BERT fine-tuned on the same training examples.
Through extensive experimentation, we show that the models trained with our
method, named SpikeBERT, outperform state-of-the-art SNNs and even achieve
comparable results to BERTs on text classification tasks for both English and
Chinese with much less energy consumption.",6
2308.12939v1,cs.LG,Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries,"Recently deep learning surrogates and neural operators have shown promise in
solving partial differential equations (PDEs). However, they often require a
large amount of training data and are limited to bounded domains. In this work,
we present a novel physics-informed neural operator method to solve
parametrized boundary value problems without labeled data. By reformulating the
PDEs into boundary integral equations (BIEs), we can train the operator network
solely on the boundary of the domain. This approach reduces the number of
required sample points from $O(N^d)$ to $O(N^{d-1})$, where $d$ is the domain's
dimension, leading to a significant acceleration of the training process.
Additionally, our method can handle unbounded problems, which are unattainable
for existing physics-informed neural networks (PINNs) and neural operators. Our
numerical experiments show the effectiveness of parametrized complex geometries
and unbounded problems.",1
2308.13028v1,quant-ph,Training Neural Networks with Universal Adiabatic Quantum Computing,"The training of neural networks (NNs) is a computationally intensive task
requiring significant time and resources. This paper presents a novel approach
to NN training using Adiabatic Quantum Computing (AQC), a paradigm that
leverages the principles of adiabatic evolution to solve optimisation problems.
We propose a universal AQC method that can be implemented on gate quantum
computers, allowing for a broad range of Hamiltonians and thus enabling the
training of expressive neural networks. We apply this approach to various
neural networks with continuous, discrete, and binary weights. Our results
indicate that AQC can very efficiently find the global minimum of the loss
function, offering a promising alternative to classical training methods.",3
2308.13214v1,math.NA,Gl-QFOM and Gl-QGMRES: two efficient algorithms for quaternion linear systems with multiple right-hand sides,"In this paper, we propose the global quaternion full orthogonalization
(Gl-QFOM) and global quaternion generalized minimum residual (Gl-QGMRES)
methods, which are built upon global orthogonal and oblique projections onto a
quaternion matrix Krylov subspace, for solving quaternion linear systems with
multiple right-hand sides. We first develop the global quaternion Arnoldi
procedure to preserve the quaternion Hessenberg form during the iterations. We
then establish the convergence analysis of the proposed methods, and show how
to apply them to solve the Sylvester quaternion matrix equation. Numerical
examples are provided to illustrate the effectiveness of our methods compared
with the traditional Gl-FOM and Gl-GMRES iterations for the real
representations of the original linear systems.",3
2308.15027v1,cs.IR,Improving Neural Ranking Models with Traditional IR Methods,"Neural ranking methods based on large transformer models have recently gained
significant attention in the information retrieval community, and have been
adopted by major commercial solutions. Nevertheless, they are computationally
expensive to create, and require a great deal of labeled data for specialized
corpora. In this paper, we explore a low resource alternative which is a
bag-of-embedding model for document retrieval and find that it is competitive
with large transformer models fine tuned on information retrieval tasks. Our
results show that a simple combination of TF-IDF, a traditional keyword
matching method, with a shallow embedding model provides a low cost path to
compete well with the performance of complex neural ranking models on 3
datasets. Furthermore, adding TF-IDF measures improves the performance of
large-scale fine tuned models on these tasks.",4
2308.13517v1,cs.CL,ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection,"Open intent detection, a crucial aspect of natural language understanding,
involves the identification of previously unseen intents in user-generated
text. Despite the progress made in this field, challenges persist in handling
new combinations of language components, which is essential for compositional
generalization. In this paper, we present a case study exploring the use of
ChatGPT as a data augmentation technique to enhance compositional
generalization in open intent detection tasks. We begin by discussing the
limitations of existing benchmarks in evaluating this problem, highlighting the
need for constructing datasets for addressing compositional generalization in
open intent detection tasks. By incorporating synthetic data generated by
ChatGPT into the training process, we demonstrate that our approach can
effectively improve model performance. Rigorous evaluation of multiple
benchmarks reveals that our method outperforms existing techniques and
significantly enhances open intent detection capabilities. Our findings
underscore the potential of large language models like ChatGPT for data
augmentation in natural language understanding tasks.",6
2308.13916v1,cs.CL,Exploring Large Language Models for Knowledge Graph Completion,"Knowledge graphs play a vital role in numerous artificial intelligence tasks,
yet they frequently face the issue of incompleteness. In this study, we explore
utilizing Large Language Models (LLM) for knowledge graph completion. We
consider triples in knowledge graphs as text sequences and introduce an
innovative framework called Knowledge Graph LLM (KG-LLM) to model these
triples. Our technique employs entity and relation descriptions of a triple as
prompts and utilizes the response for predictions. Experiments on various
benchmark knowledge graphs demonstrate that our method attains state-of-the-art
performance in tasks such as triple classification and relation prediction. We
also find that fine-tuning relatively smaller models (e.g., LLaMA-7B,
ChatGLM-6B) outperforms recent ChatGPT and GPT-4.",6
2308.13958v1,cs.CL,"Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning","The use of large transformer-based models such as BERT, GPT, and T5 has led
to significant advancements in natural language processing. However, these
models are computationally expensive, necessitating model compression
techniques that reduce their size and complexity while maintaining accuracy.
This project investigates and applies knowledge distillation for BERT model
compression, specifically focusing on the TinyBERT student model. We explore
various techniques to improve knowledge distillation, including experimentation
with loss functions, transformer layer mapping methods, and tuning the weights
of attention and representation loss and evaluate our proposed techniques on a
selection of downstream tasks from the GLUE benchmark. The goal of this work is
to improve the efficiency and effectiveness of knowledge distillation, enabling
the development of more efficient and accurate models for a range of natural
language processing tasks.",8
2308.14186v1,cs.CL,Empowering Cross-lingual Abilities of Instruction-tuned Large Language Models by Translation-following demonstrations,"The language ability of Large Language Models (LLMs) is often unbalanced
towards English because of the imbalance in the distribution of the
pre-training data. This disparity is demanded in further fine-tuning and
affecting the cross-lingual abilities of LLMs. In this paper, we propose to
empower Instructiontuned LLMs (It-LLMs) in languages other than English by
building semantic alignment between them. Hence, we propose CrossAlpaca, an
It-LLM with cross-lingual instruction-following and Translation-following
demonstrations to improve semantic alignment between languages. We validate our
approach on the multilingual Question Answering (QA) benchmarks XQUAD and MLQA
and adapted versions of MMLU and BBH. Our models, tested over six different
languages, outperform the It-LLMs tuned on monolingual data. The final results
show that instruction tuning on non-English data is not enough and that
semantic alignment can be further improved by Translation-following
demonstrations.",2
2308.14995v1,cs.CV,WSAM: Visual Explanations from Style Augmentation as Adversarial Attacker and Their Influence in Image Classification,"Currently, style augmentation is capturing attention due to convolutional
neural networks (CNN) being strongly biased toward recognizing textures rather
than shapes. Most existing styling methods either perform a low-fidelity style
transfer or a weak style representation in the embedding vector. This paper
outlines a style augmentation algorithm using stochastic-based sampling with
noise addition to improving randomization on a general linear transformation
for style transfer. With our augmentation strategy, all models not only present
incredible robustness against image stylizing but also outperform all previous
methods and surpass the state-of-the-art performance for the STL-10 dataset. In
addition, we present an analysis of the model interpretations under different
style variations. At the same time, we compare comprehensive experiments
demonstrating the performance when applied to deep neural architectures in
training settings.",5
2308.14641v2,cs.CL,Challenges of GPT-3-based Conversational Agents for Healthcare,"The potential to provide patients with faster information access while
allowing medical specialists to concentrate on critical tasks makes medical
domain dialog agents appealing. However, the integration of large-language
models (LLMs) into these agents presents certain limitations that may result in
serious consequences. This paper investigates the challenges and risks of using
GPT-3-based models for medical question-answering (MedQA). We perform several
evaluations contextualized in terms of standard medical principles. We provide
a procedure for manually designing patient queries to stress-test high-risk
limitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to
respond adequately to these queries, generating erroneous medical information,
unsafe recommendations, and content that may be considered offensive.",5
2308.14634v1,cs.CL,Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance,"We propose the use of conversational GPT models for easy and quick few-shot
text classification in the financial domain using the Banking77 dataset. Our
approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes
the technical expertise required and eliminates the need for expensive GPU
computing while yielding quick and accurate results. Additionally, we fine-tune
other pre-trained, masked language models with SetFit, a recent contrastive
learning technique, to achieve state-of-the-art results both in full-data and
few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can
outperform fine-tuned, non-generative models even with fewer examples. However,
subscription fees associated with these solutions may be considered costly for
small organizations. Lastly, we find that generative models perform better on
the given task when shown representative samples selected by a human expert
rather than when shown random ones. We conclude that a) our proposed methods
offer a practical solution for few-shot tasks in datasets with limited label
availability, and b) our state-of-the-art results can inspire future work in
the area.",6
2308.15232v1,cs.LG,Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification,"A large number of conflict events are affecting the world all the time. In
order to analyse such conflict events effectively, this paper presents a
Classification-Aware Neural Topic Model (CANTM-IA) for Conflict Information
Classification and Topic Discovery. The model provides a reliable
interpretation of classification results and discovered topics by introducing
interpretability analysis. At the same time, interpretation is introduced into
the model architecture to improve the classification performance of the model
and to allow interpretation to focus further on the details of the data.
Finally, the model architecture is optimised to reduce the complexity of the
model.",6
2308.13782v1,cs.CL,Planning with Logical Graph-based Language Model for Instruction Generation,"Despite the superior performance of large language models to generate natural
language texts, it is hard to generate texts with correct logic according to a
given task, due to the difficulties for neural models to capture implied rules
from free-form texts. In this paper, we propose a novel graph-based language
model, Logical-GLM, to infuse logic into language models for more valid text
generation and interpretability. Specifically, we first capture information
from natural language instructions and construct logical bayes graphs that
generally describe domains. Next, we generate logical skeletons to guide
language model training, infusing domain knowledge into language models.
Finally, we alternately optimize the searching policy of graphs and language
models until convergence. The experimental results show that Logical-GLM is
both effective and efficient compared with traditional language models, despite
using smaller-scale training data and fewer parameters. Our approach can
generate instructional texts with more correct logic owing to the internalized
domain knowledge. Moreover, the usage of logical graphs reflects the inner
mechanism of the language models, which improves the interpretability of
black-box models.",4
2308.15126v1,cs.LG,Evaluation and Analysis of Hallucination in Large Vision-Language Models,"Large Vision-Language Models (LVLMs) have recently achieved remarkable
success. However, LVLMs are still plagued by the hallucination problem, which
limits the practicality in many scenarios. Hallucination refers to the
information of LVLMs' responses that does not exist in the visual input, which
poses potential risks of substantial consequences. There has been limited work
studying hallucination evaluation in LVLMs. In this paper, we propose
Hallucination Evaluation based on Large Language Models (HaELM), an LLM-based
hallucination evaluation framework. HaELM achieves an approximate 95%
performance comparable to ChatGPT and has additional advantages including low
cost, reproducibility, privacy preservation and local deployment. Leveraging
the HaELM, we evaluate the hallucination in current LVLMs. Furthermore, we
analyze the factors contributing to hallucination in LVLMs and offer helpful
suggestions to mitigate the hallucination problem. Our training data and human
annotation hallucination data will be made public soon.",9
2308.15214v1,cs.CL,"FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions","We demonstrate an embodied conversational agent that can function as a
receptionist and generate a mixture of open and closed-domain dialogue along
with facial expressions, by using a large language model (LLM) to develop an
engaging conversation. We deployed the system onto a Furhat robot, which is
highly expressive and capable of using both verbal and nonverbal cues during
interaction. The system was designed specifically for the National Robotarium
to interact with visitors through natural conversations, providing them with
information about the facilities, research, news, upcoming events, etc. The
system utilises the state-of-the-art GPT-3.5 model to generate such information
along with domain-general conversations and facial expressions based on prompt
engineering.",7
2308.11580v1,physics.comp-ph,NIPG-DG schemes for transformed master equations modeling open quantum systems,"This work presents a numerical analysis of a master equation modeling the
interaction of a system with a noisy environment in the particular context of
open quantum systems. It is shown that our transformed master equation has a
reduced computational cost in comparison to a Wigner-Fokker-Planck model of the
same system for the general case of any potential. Specifics of a NIPG-DG
numerical scheme adequate for the convection-diffusion system obtained are then
presented. This will let us solve computationally the transformed system of
interest modeling our open quantum system. A benchmark problem, the case of a
harmonic potential, is then presented, for which the numerical results are
compared against the analytical steady-state solution of this problem.",3
2308.13986v1,math.NA,A Deep Learning Method for Computing Eigenvalues of the Fractional Schr√∂dinger Operator,"We present a novel deep learning method for computing eigenvalues of the
fractional Schr\""odinger operator. Our approach combines a newly developed loss
function with an innovative neural network architecture that incorporates prior
knowledge of the problem. These improvements enable our method to handle both
high-dimensional problems and problems posed on irregular bounded domains. We
successfully compute up to the first 30 eigenvalues for various fractional
Schr\""odinger operators. As an application, we share a conjecture to the
fractional order isospectral problem that has not yet been studied.",2
2308.14902v1,cs.IR,Ad-Rec: Advanced Feature Interactions to Address Covariate-Shifts in Recommendation Networks,"Recommendation models are vital in delivering personalized user experiences
by leveraging the correlation between multiple input features. However, deep
learning-based recommendation models often face challenges due to evolving user
behaviour and item features, leading to covariate shifts. Effective
cross-feature learning is crucial to handle data distribution drift and
adapting to changing user behaviour. Traditional feature interaction techniques
have limitations in achieving optimal performance in this context.
  This work introduces Ad-Rec, an advanced network that leverages feature
interaction techniques to address covariate shifts. This helps eliminate
irrelevant interactions in recommendation tasks. Ad-Rec leverages masked
transformers to enable the learning of higher-order cross-features while
mitigating the impact of data distribution drift. Our approach improves model
quality, accelerates convergence, and reduces training time, as measured by the
Area Under Curve (AUC) metric. We demonstrate the scalability of Ad-Rec and its
ability to achieve superior model quality through comprehensive ablation
studies.",6
2308.15409v1,math.NA,An Incremental SVD Method for Non-Fickian Flows in Porous Media: Addressing Storage and Computational Challenges,"It is well known that the numerical solution of the Non-Fickian flows at the
current stage depends on all previous time instances. Consequently, the storage
requirement increases linearly, while the computational complexity grows
quadratically with the number of time steps. This presents a significant
challenge for numerical simulations, and to the best of our knowledge, it
remains an unresolved issue. In this paper, we present a memory-free algorithm,
based on the incremental SVD technique, that exhibits only linear growth in
computational complexity as the number of time steps increases. We prove that
the error between the solutions generated by the conventional algorithm and our
innovative approach lies within the scope of machine error. Numerical
experiments are showcased to affirm the accuracy and efficiency gains in terms
of both memory usage and computational expenses.",2
2308.15050v1,cs.CV,iBARLE: imBalance-Aware Room Layout Estimation,"Room layout estimation predicts layouts from a single panorama. It requires
datasets with large-scale and diverse room shapes to train the models. However,
there are significant imbalances in real-world datasets including the
dimensions of layout complexity, camera locations, and variation in scene
appearance. These issues considerably influence the model training performance.
In this work, we propose the imBalance-Aware Room Layout Estimation (iBARLE)
framework to address these issues. iBARLE consists of (1) Appearance Variation
Generation (AVG) module, which promotes visual appearance domain
generalization, (2) Complex Structure Mix-up (CSMix) module, which enhances
generalizability w.r.t. room structure, and (3) a gradient-based layout
objective function, which allows more effective accounting for occlusions in
complex layouts. All modules are jointly trained and help each other to achieve
the best performance. Experiments and ablation studies based on
ZInD~\cite{cruz2021zillow} dataset illustrate that iBARLE has state-of-the-art
performance compared with other layout estimation baselines.",1
2308.14436v1,cs.CL,Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA,"Knowledge Base Question Answering (KBQA) aims to answer natural language
questions with factual information such as entities and relations in KBs.
However, traditional Pre-trained Language Models (PLMs) are directly
pre-trained on large-scale natural language corpus, which poses challenges for
them in understanding and representing complex subgraphs in structured KBs. To
bridge the gap between texts and structured KBs, we propose a Structured
Knowledge-aware Pre-training method (SKP). In the pre-training stage, we
introduce two novel structured knowledge-aware tasks, guiding the model to
effectively learn the implicit relationship and better representations of
complex subgraphs. In downstream KBQA task, we further design an efficient
linearization strategy and an interval attention mechanism, which assist the
model to better encode complex subgraphs and shield the interference of
irrelevant subgraphs during reasoning respectively. Detailed experiments and
analyses on WebQSP verify the effectiveness of SKP, especially the significant
improvement in subgraph retrieval (+4.08% H@10).",1
2308.15096v1,cs.LG,How Faithful are Self-Explainable GNNs?,"Self-explainable deep neural networks are a recent class of models that can
output ante-hoc local explanations that are faithful to the model's reasoning,
and as such represent a step forward toward filling the gap between
expressiveness and interpretability. Self-explainable graph neural networks
(GNNs) aim at achieving the same in the context of graph data. This begs the
question: do these models fulfill their implicit guarantees in terms of
faithfulness? In this extended abstract, we analyze the faithfulness of several
self-explainable GNNs using different measures of faithfulness, identify
several limitations -- both in the models themselves and in the evaluation
metrics -- and outline possible ways forward.",1
2308.15106v1,math.NA,On factorization of rank-one auto-correlation matrix polynomials,"This article characterizes the rank-one factorization of auto-correlation
matrix polynomials. We establish a sufficient and necessary uniqueness
condition for uniqueness of the factorization based on the greatest common
divisor (GCD) of multiple polynomials. In the unique case, we show that the
factorization can be carried out explicitly using GCDs. In the non-unique case,
the number of non-trivially different factorizations is given and all solutions
are enumerated.",1
2308.15055v1,cs.CL,Taxonomic Loss for Morphological Glossing of Low-Resource Languages,"Morpheme glossing is a critical task in automated language documentation and
can benefit other downstream applications greatly. While state-of-the-art
glossing systems perform very well for languages with large amounts of existing
data, it is more difficult to create useful models for low-resource languages.
In this paper, we propose the use of a taxonomic loss function that exploits
morphological information to make morphological glossing more performant when
data is scarce. We find that while the use of this loss function does not
outperform a standard loss function with regards to single-label prediction
accuracy, it produces better predictions when considering the top-n predicted
labels. We suggest this property makes the taxonomic loss function useful in a
human-in-the-loop annotation setting.",1
2308.14948v1,astro-ph.IM,Machine Learning for Mini-EUSO Telescope Data Analysis,"Neural networks as well as other methods of machine learning (ML) are known
to be highly efficient in different classification tasks, including
classification of images and videos. Mini- EUSO is a wide-field-of-view imaging
telescope that operates onboard the International Space Station since 2019
collecting data on miscellaneous processes that take place in the atmosphere of
Earth in the UV range. Here we briefly present our results on the development
of ML-based approaches for recognition and classification of track-like signals
in the Mini-EUSO data, among them meteors, space debris and signals the light
curves and kinematics of which are similar to those expected from extensive air
showers generated by ultra-high-energy cosmic rays. We show that even simple
neural networks demonstrate impressive performance in solving these tasks.",1
2308.15434v1,cs.LG,Random feature approximation for general spectral methods,"Random feature approximation is arguably one of the most popular techniques
to speed up kernel methods in large scale algorithms and provides a theoretical
approach to the analysis of deep neural networks. We analyze generalization
properties for a large class of spectral regularization methods combined with
random features, containing kernel methods with implicit regularization such as
gradient descent or explicit methods like Tikhonov regularization. For our
estimators we obtain optimal learning rates over regularity classes (even for
classes that are not included in the reproducing kernel Hilbert space), which
are defined through appropriate source conditions. This improves or completes
previous results obtained in related settings for specific kernel algorithms.",1
2308.13961v1,cs.CL,"Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models","To translate well, machine translation (MT) systems and general-purposed
language models (LMs) need a deep understanding of both source and target
languages and cultures. Therefore, idioms, with their non-compositional nature,
pose particular challenges for Transformer-based systems, as literal
translations often miss the intended meaning. Traditional methods, which
replace idioms using existing knowledge bases (KBs), often lack scale and
context awareness. Addressing these challenges, our approach prioritizes
context awareness and scalability, allowing for offline storage of idioms in a
manageable KB size. This ensures efficient serving with smaller models and
provides a more comprehensive understanding of idiomatic expressions. We
introduce a multilingual idiom KB (IdiomKB) developed using large LMs to
address this. This KB facilitates better translation by smaller models, such as
BLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms'
figurative meanings. We present a novel, GPT-4-powered metric for human-aligned
evaluation, demonstrating that IdiomKB considerably boosts model performance.
Human evaluations further validate our KB's quality.",1
2308.14893v1,cs.CV,When hard negative sampling meets supervised contrastive learning,"State-of-the-art image models predominantly follow a two-stage strategy:
pre-training on large datasets and fine-tuning with cross-entropy loss. Many
studies have shown that using cross-entropy can result in sub-optimal
generalisation and stability. While the supervised contrastive loss addresses
some limitations of cross-entropy loss by focusing on intra-class similarities
and inter-class differences, it neglects the importance of hard negative
mining. We propose that models will benefit from performance improvement by
weighting negative samples based on their dissimilarity to positive
counterparts. In this paper, we introduce a new supervised contrastive learning
objective, SCHaNe, which incorporates hard negative sampling during the
fine-tuning phase. Without requiring specialized architectures, additional
data, or extra computational resources, experimental results indicate that
SCHaNe outperforms the strong baseline BEiT-3 in Top-1 accuracy across various
benchmarks, with significant gains of up to $3.32\%$ in few-shot learning
settings and $3.41\%$ in full dataset fine-tuning. Importantly, our proposed
objective sets a new state-of-the-art for base models on ImageNet-1k, achieving
an 86.14\% accuracy. Furthermore, we demonstrate that the proposed objective
yields better embeddings and explains the improved effectiveness observed in
our experiments.",1
2308.14981v1,quant-ph,Sub-universal variational circuits for combinatorial optimization problems,"Quantum variational circuits have gained significant attention due to their
applications in the quantum approximate optimization algorithm and quantum
machine learning research. This work introduces a novel class of classical
probabilistic circuits designed for generating approximate solutions to
combinatorial optimization problems constructed using two-bit stochastic
matrices. Through a numerical study, we investigate the performance of our
proposed variational circuits in solving the Max-Cut problem on various graphs
of increasing sizes. Our classical algorithm demonstrates improved performance
for several graph types to the quantum approximate optimization algorithm. Our
findings suggest that evaluating the performance of quantum variational
circuits against variational circuits with sub-universal gate sets is a
valuable benchmark for identifying areas where quantum variational circuits can
excel.",1
2308.11533v1,math.NA,Lifting Sylvester equations: singular value decay for non-normal coefficients,"We aim to find conditions on two Hilbert space operators $A$ and $B$ under
which the expression $AX-XB$ having low rank forces the operator $X$ itself to
admit a good low rank approximation. It is known that this can be achieved when
$A$ and $B$ are normal and have well-separated spectra. In this paper, we relax
this normality condition, using the idea of operator dilations. The basic
problem then becomes the lifting of Sylvester equations, which is reminiscent
of the classical commutant lifting theorem and its variations. Our approach
also allows us to show that the (factored) alternating direction implicit
method for solving Sylvester equaftions $AX-XB=C$ does not require too many
iterations, even without requiring $A$ to be normal.",1
2308.14182v1,cs.CL,Generative AI for Business Strategy: Using Foundation Models to Create Business Strategy Tools,"Generative models (foundation models) such as LLMs (large language models)
are having a large impact on multiple fields. In this work, we propose the use
of such models for business decision making. In particular, we combine
unstructured textual data sources (e.g., news data) with multiple foundation
models (namely, GPT4, transformer-based Named Entity Recognition (NER) models
and Entailment-based Zero-shot Classifiers (ZSC)) to derive IT (information
technology) artifacts in the form of a (sequence of) signed business networks.
We posit that such artifacts can inform business stakeholders about the state
of the market and their own positioning as well as provide quantitative
insights into improving their future outlook.",9
2308.14903v1,cs.CL,MEMORY-VQ: Compression for Tractable Internet-Scale Memory,"Retrieval augmentation is a powerful but expensive method to make language
models more knowledgeable about the world. Memory-based methods like LUMEN
pre-compute token representations for retrieved passages to drastically speed
up inference. However, memory also leads to much greater storage requirements
from storing pre-computed representations.
  We propose MEMORY-VQ, a new method to reduce storage requirements of
memory-augmented models without sacrificing performance. Our method uses a
vector quantization variational autoencoder (VQ-VAE) to compress token
representations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a
memory model that achieves a 16x compression rate with comparable performance
on the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even
for extremely large retrieval corpora.",3
2308.15116v1,cs.LG,Mixup-Augmented Meta-Learning for Sample-Efficient Fine-Tuning of Protein Simulators,"Molecular dynamics simulations have emerged as a fundamental instrument for
studying biomolecules. At the same time, it is desirable to perform simulations
of a collection of particles under various conditions in which the molecules
can fluctuate. In this paper, we explore and adapt the soft prompt-based
learning method to molecular dynamics tasks. Our model can remarkably
generalize to unseen and out-of-distribution scenarios with limited training
data. While our work focuses on temperature as a test case, the versatility of
our approach allows for efficient simulation through any continuous dynamic
conditions, such as pressure and volumes. Our framework has two stages: 1)
Pre-trains with data mixing technique, augments molecular structure data and
temperature prompts, then applies a curriculum learning method by increasing
the ratio of them smoothly. 2) Meta-learning-based fine-tuning framework
improves sample-efficiency of fine-tuning process and gives the soft
prompt-tuning better initialization points. Comprehensive experiments reveal
that our framework excels in accuracy for in-domain data and demonstrates
strong generalization capabilities for unseen and out-of-distribution samples.",2
2308.15041v1,math.NA,Optimization via conformal Hamiltonian systems on manifolds,"In this work we propose a method to perform optimization on manifolds. We
assume to have an objective function $f$ defined on a manifold and think of it
as the potential energy of a mechanical system. By adding a momentum-dependent
kinetic energy we define its Hamiltonian function, which allows us to write the
corresponding Hamiltonian system. We make it conformal by introducing a
dissipation term: the result is the continuous model of our scheme. We solve it
via splitting methods (Lie-Trotter and leapfrog): we combine the RATTLE scheme,
approximating the conserved flow, with the exact dissipated flow. The result is
a conformal symplectic method for constant stepsizes. We also propose an
adaptive stepsize version of it. We test it on an example, the minimization of
a function defined on a sphere, and compare it with the usual gradient descent
method.",2
2308.14337v1,cs.AI,Cognitive Effects in Large Language Models,"Large Language Models (LLMs) such as ChatGPT have received enormous attention
over the past year and are now used by hundreds of millions of people every
day. The rapid adoption of this technology naturally raises questions about the
possible biases such models might exhibit. In this work, we tested one of these
models (GPT-3) on a range of cognitive effects, which are systematic patterns
that are usually found in human cognitive tasks. We found that LLMs are indeed
prone to several human cognitive effects. Specifically, we show that the
priming, distance, SNARC, and size congruity effects were presented with GPT-3,
while the anchoring effect is absent. We describe our methodology, and
specifically the way we converted real-world experiments to text-based
experiments. Finally, we speculate on the possible reasons why GPT-3 exhibits
these effects and discuss whether they are imitated or reinvented.",10
2308.13911v1,cs.AI,A Wide Evaluation of ChatGPT on Affective Computing Tasks,"With the rise of foundation models, a new artificial intelligence paradigm
has emerged, by simply using general purpose foundation models with prompting
to solve problems instead of training a separate machine learning model for
each problem. Such models have been shown to have emergent properties of
solving problems that they were not initially trained on. The studies for the
effectiveness of such models are still quite limited. In this work, we widely
study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13
affective computing problems, namely aspect extraction, aspect polarity
classification, opinion extraction, sentiment analysis, sentiment intensity
ranking, emotions intensity ranking, suicide tendency detection, toxicity
detection, well-being assessment, engagement measurement, personality
assessment, sarcasm detection, and subjectivity detection. We introduce a
framework to evaluate the ChatGPT models on regression-based problems, such as
intensity ranking problems, by modelling them as pairwise ranking
classification. We compare ChatGPT against more traditional NLP methods, such
as end-to-end recurrent neural networks and transformers. The results
demonstrate the emergent abilities of the ChatGPT models on a wide range of
affective computing problems, where GPT-3.5 and especially GPT-4 have shown
strong performance on many problems, particularly the ones related to
sentiment, emotions, or toxicity. The ChatGPT models fell short for problems
with implicit signals, such as engagement measurement and subjectivity
detection.",10
2308.12724v1,hep-ex,Jet energy calibration with deep learning as a Kubeflow pipeline,"Precise measurements of the energy of jets emerging from particle collisions
at the LHC are essential for a vast majority of physics searches at the CMS
experiment. In this study, we leverage well-established deep learning models
for point clouds and CMS open data to improve the energy calibration of
particle jets. To enable production-ready machine learning based jet energy
calibration an end-to-end pipeline is built on the Kubeflow cloud platform. The
pipeline allowed us to scale up our hyperparameter tuning experiments on cloud
resources, and serve optimal models as REST endpoints. We present the results
of the parameter tuning process and analyze the performance of the served
models in terms of inference time and overhead, providing insights for future
work in this direction. The study also demonstrates improvements in both flavor
dependence and resolution of the energy response when compared to the standard
jet energy corrections baseline.",3
2308.14938v1,cs.CV,Entropy-based Guidance of Deep Neural Networks for Accelerated Convergence and Improved Performance,"Neural networks have dramatically increased our capacity to learn from large,
high-dimensional datasets across innumerable disciplines. However, their
decisions are not easily interpretable, their computational costs are high, and
building and training them are uncertain processes. To add structure to these
efforts, we derive new mathematical results to efficiently measure the changes
in entropy as fully-connected and convolutional neural networks process data,
and introduce entropy-based loss terms. Experiments in image compression and
image classification on benchmark datasets demonstrate these losses guide
neural networks to learn rich latent data representations in fewer dimensions,
converge in fewer training epochs, and achieve better test metrics.",8
2308.14149v1,cs.CL,"Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models","Generative pre-trained transformer (GPT) models have revolutionized the field
of natural language processing (NLP) with remarkable performance in various
tasks and also extend their power to multimodal domains. Despite their success,
large GPT models like GPT-4 face inherent limitations such as considerable
size, high computational requirements, complex deployment processes, and closed
development loops. These constraints restrict their widespread adoption and
raise concerns regarding their responsible development and usage. The need for
user-friendly, relatively small, and open-sourced alternative GPT models arises
from the desire to overcome these limitations while retaining high performance.
In this survey paper, we provide an examination of alternative open-sourced
models of large GPTs, focusing on user-friendly and relatively small models
that facilitate easier deployment and accessibility. Through this extensive
survey, we aim to equip researchers, practitioners, and enthusiasts with a
thorough understanding of user-friendly and relatively small open-sourced
models of large GPTs, their current state, challenges, and future research
directions, inspiring the development of more efficient, accessible, and
versatile GPT models that cater to the broader scientific community and advance
the field of general artificial intelligence. The source contents are
continuously updating in https://github.com/GPT-Alternatives/gpt_alternatives.",6
2308.15364v1,cs.LG,Heterogeneous Multi-Task Gaussian Cox Processes,"This paper presents a novel extension of multi-task Gaussian Cox processes
for modeling multiple heterogeneous correlated tasks jointly, e.g.,
classification and regression, via multi-output Gaussian processes (MOGP). A
MOGP prior over the parameters of the dedicated likelihoods for classification,
regression and point process tasks can facilitate sharing of information
between heterogeneous tasks, while allowing for nonparametric parameter
estimation. To circumvent the non-conjugate Bayesian inference in the MOGP
modulated heterogeneous multi-task framework, we employ the data augmentation
technique and derive a mean-field approximation to realize closed-form
iterative updates for estimating model parameters. We demonstrate the
performance and inference on both 1D synthetic data as well as 2D urban data of
Vancouver.",1
2308.15466v1,cs.LG,Input margins can predict generalization too,"Understanding generalization in deep neural networks is an active area of
research. A promising avenue of exploration has been that of margin
measurements: the shortest distance to the decision boundary for a given sample
or its representation internal to the network. While margins have been shown to
be correlated with the generalization ability of a model when measured at its
hidden representations (hidden margins), no such link between large margins and
generalization has been established for input margins. We show that while input
margins are not generally predictive of generalization, they can be if the
search space is appropriately constrained. We develop such a measure based on
input margins, which we refer to as `constrained margins'. The predictive power
of this new measure is demonstrated on the 'Predicting Generalization in Deep
Learning' (PGDL) dataset and contrasted with hidden representation margins. We
find that constrained margins achieve highly competitive scores and outperform
other margin measurements in general. This provides a novel insight on the
relationship between generalization and classification margins, and highlights
the importance of considering the data manifold for investigations of
generalization in DNNs.",1
2308.14407v1,physics.optics,Identifying topology of leaky photonic lattices with machine learning,"We show how machine learning techniques can be applied for the classification
of topological phases in leaky photonic lattices using limited measurement
data. We propose an approach based solely on bulk intensity measurements, thus
exempt from the need for complicated phase retrieval procedures. In particular,
we design a fully connected neural network that accurately determines
topological properties from the output intensity distribution in dimerized
waveguide arrays with leaky channels, after propagation of a spatially
localized initial excitation at a finite distance, in a setting that closely
emulates realistic experimental conditions.",1
2308.14864v1,cs.LG,NAS-X: Neural Adaptive Smoothing via Twisting,"We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for
learning and inference in sequential latent variable models based on reweighted
wake-sleep (RWS). NAS-X works with both discrete and continuous latent
variables, and leverages smoothing SMC to fit a broader range of models than
traditional RWS methods. We test NAS-X on discrete and continuous tasks and
find that it substantially outperforms previous variational and RWS-based
methods in inference and parameter recovery.",1
2308.14359v1,cs.AI,Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks,"Human emotion understanding is pivotal in making conversational technology
mainstream. We view speech emotion understanding as a perception task which is
a more realistic setting. With varying contexts (languages, demographics, etc.)
different share of people perceive the same speech segment as a non-unanimous
emotion. As part of the ACM Multimedia 2023 Computational Paralinguistics
ChallengE (ComParE) in the EMotion Share track, we leverage their rich dataset
of multilingual speakers and multi-label regression target of 'emotion share'
or perception of that emotion. We demonstrate that the training scheme of
different foundation models dictates their effectiveness for tasks beyond
speech recognition, especially for non-semantic speech tasks like emotion
  understanding. This is a very complex task due to multilingual speakers,
variability in the target labels, and inherent imbalance in the regression
dataset. Our results show that HuBERT-Large with a self-attention-based
light-weight sequence model provides 4.6% improvement over the reported
baseline.",8
2308.15448v1,cs.CL,Vulgar Remarks Detection in Chittagonian Dialect of Bangla,"The negative effects of online bullying and harassment are increasing with
Internet popularity, especially in social media. One solution is using natural
language processing (NLP) and machine learning (ML) methods for the automatic
detection of harmful remarks, but these methods are limited in low-resource
languages like the Chittagonian dialect of Bangla.This study focuses on
detecting vulgar remarks in social media using supervised ML and deep learning
algorithms.Logistic Regression achieved promising accuracy (0.91) while simple
RNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the
issue that NN algorithms require more data.",6
2308.12891v1,math.NA,A class of Discontinuous Galerkin methods for nonlinear variational problems,"In the context of Discontinuous Galerkin methods, we study approximations of
nonlinear variational problems associated with convex energies. We propose
element-wise nonconforming finite element methods to discretize the continuous
minimisation problem. Using $\Gamma$-convergence arguments we show that the
discrete minimisers converge to the unique minimiser of the continuous problem
as the mesh parameter tends to zero, under the additional contribution of
appropriately defined penalty terms at the level of the discrete energies. We
finally substantiate the feasibility of our methods by numerical examples.",2
2308.15262v1,cs.CV,Enhancing OCR Performance through Post-OCR Models: Adopting Glyph Embedding for Improved Correction,"The study investigates the potential of post-OCR models to overcome
limitations in OCR models and explores the impact of incorporating glyph
embedding on post-OCR correction performance. In this study, we have developed
our own post-OCR correction model. The novelty of our approach lies in
embedding the OCR output using CharBERT and our unique embedding technique,
capturing the visual characteristics of characters. Our findings show that
post-OCR correction effectively addresses deficiencies in inferior OCR models,
and glyph embedding enables the model to achieve superior results, including
the ability to correct individual words.",1
2308.13096v1,cond-mat.mtrl-sci,Electronic Structure Prediction of Multi-million Atom Systems Through Uncertainty Quantification Enabled Transfer Learning,"The ground state electron density - obtainable using Kohn-Sham Density
Functional Theory (KS-DFT) simulations - contains a wealth of material
information, making its prediction via machine learning (ML) models attractive.
However, the computational expense of KS-DFT scales cubically with system size
which tends to stymie training data generation, making it difficult to develop
quantifiably accurate ML models that are applicable across many scales and
system configurations. Here, we address these fundamental challenges using
Bayesian neural networks and employ transfer learning to leverage the
multi-scale nature of the training data. Our ML models employ descriptors
involving simple scalar products, comprehensively sample system configurations
through thermalization, and quantify uncertainty in electron density
predictions. We show that our models incur significantly lower data generation
costs while allowing confident - and when verifiable, accurate - predictions
for a wide variety of bulk systems well beyond training, including systems with
defects, different alloy compositions, and at unprecedented, multi-million-atom
scales.",2
2308.14120v2,cs.LG,Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies,"A knowledge gap persists between Machine Learning (ML) developers (e.g., data
scientists) and practitioners (e.g., clinicians), hampering the full
utilization of ML for clinical data analysis. We investigated the potential of
the chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this
gap and perform ML analyses efficiently. Real-world clinical datasets and study
details from large trials across various medical specialties were presented to
chatGPT ADA without specific guidance. ChatGPT ADA autonomously developed
state-of-the-art ML models based on the original study's training data to
predict clinical outcomes such as cancer development, cancer progression,
disease complications, or biomarkers such as pathogenic gene sequences.
Strikingly, these ML models matched or outperformed their published
counterparts. We conclude that chatGPT ADA offers a promising avenue to
democratize ML in medicine, making advanced analytics accessible to non-ML
experts and promoting broader applications in medical research and practice.",1
2308.15182v1,math.NA,Stabilised finite element method for Stokes problem with nonlinear slip condition,"This work introduces a stabilised finite element formulation for the Stokes
flow problem with a nonlinear slip boundary condition of friction type. The
boundary condition is enforced with the help of an additional Lagrange
multiplier and the stabilised formulation is based on simultaneously
stabilising both the pressure and the Lagrange multiplier. We establish the
stability and the a priori error analyses, and perform a numerical convergence
study in order to verify the theory.",1
2308.14423v1,cs.CL,GADePo: Graph-Assisted Declarative Pooling Transformers for Document-Level Relation Extraction,"Document-level relation extraction aims to identify relationships between
entities within a document. Current methods rely on text-based encoders and
employ various hand-coded pooling heuristics to aggregate information from
entity mentions and associated contexts. In this paper, we replace these rigid
pooling functions with explicit graph relations by leveraging the intrinsic
graph processing capabilities of the Transformer model. We propose a joint
text-graph Transformer model, and a graph-assisted declarative pooling (GADePo)
specification of the input which provides explicit and high-level instructions
for information aggregation. This allows the pooling process to be guided by
domain-specific knowledge or desired outcomes but still learned by the
Transformer, leading to more flexible and customizable pooling strategies. We
extensively evaluate our method across diverse datasets and models, and show
that our approach yields promising results that are comparable to those
achieved by the hand-coded pooling functions.",5
2308.12325v1,q-bio.QM,Predicting Drug Solubility Using Different Machine Learning Methods -- Linear Regression Model with Extracted Chemical Features vs Graph Convolutional Neural Network,"Predicting the solubility of given molecules is an important task in the
pharmaceutical industry, and consequently this is a well-studied topic. In this
research, we revisited this problem with the advantage of modern computing
resources. We applied two machine learning models, a linear regression model
and a graph convolutional neural network model, on multiple experimental
datasets. Both methods can make reasonable predictions while the GCNN model had
the best performance. However, the current GCNN model is a black box, while
feature importance analysis from the linear regression model offers more
insights into the underlying chemical influences. Using the linear regression
model, we show how each functional group affects the overall solubility.
Ultimately, knowing how chemical structure influences chemical properties is
crucial when designing new drugs. Future work should aim to combine the high
performance of GCNNs with the interpretability of linear regression, unlocking
new advances in next generation high throughput screening.",6
2308.15299v1,cs.CL,TaskLAMA: Probing the Complex Task Understanding of Language Models,"Structured Complex Task Decomposition (SCTD) is the problem of breaking down
a complex real-world task (such as planning a wedding) into a directed acyclic
graph over individual steps that contribute to achieving the task, with edges
specifying temporal dependencies between them. SCTD is an important component
of assistive planning tools, and a challenge for commonsense reasoning systems.
We probe how accurately SCTD can be done with the knowledge extracted from
Large Language Models (LLMs). We introduce a high-quality human-annotated
dataset for this problem and novel metrics to fairly assess performance of LLMs
against several baselines. Our experiments reveal that LLMs are able to
decompose complex tasks into individual steps effectively, with a relative
improvement of 15% to 280% over the best baseline. We also propose a number of
approaches to further improve their performance, with a relative improvement of
7% to 37% over the base model. However, we find that LLMs still struggle to
predict pairwise temporal dependencies, which reveals a gap in their
understanding of complex tasks.",7
2308.15301v1,physics.data-an,Convexity constraints on linear background models for electron energy-loss spectra,"In this paper convexity constraints are derived for a background model of
electron energy loss spectra (EELS) that is linear in the fitting parameters.
The model outperforms a power-law both on experimental and simulated
backgrounds, especially for wide energy ranges, and thus improves elemental
quantification results. Owing to the model's linearity, the constraints can be
imposed through fitting by quadratic programming. This has important advantages
over conventional nonlinear power-law fitting such as high speed, not requiring
initial parameters, and a guaranteed unique solution. As such, the need for
user input is significantly reduced, which is essential for unsupervised
treatment of large data sets. This is demonstrated on a demanding spectrum
image of a semiconductor device sample with a high number of elements over a
wide energy range.",2
2308.14972v1,cs.RO,LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks,"This paper presents a novel approach to enhance autonomous robotic
manipulation using the Large Language Model (LLM) for logical inference,
converting high-level language commands into sequences of executable motion
functions. The proposed system combines the advantage of LLM with YOLO-based
environmental perception to enable robots to autonomously make reasonable
decisions and task planning based on the given commands. Additionally, to
address the potential inaccuracies or illogical actions arising from LLM, a
combination of teleoperation and Dynamic Movement Primitives (DMP) is employed
for action correction. This integration aims to improve the practicality and
generalizability of the LLM-based human-robot collaboration system.",6
2308.14904v1,cs.CV,Maturity-Aware Active Learning for Semantic Segmentation with Hierarchically-Adaptive Sample Assessment,"Active Learning (AL) for semantic segmentation is challenging due to heavy
class imbalance and different ways of defining ""sample"" (pixels, areas, etc.),
leaving the interpretation of the data distribution ambiguous. We propose
""Maturity-Aware Distribution Breakdown-based Active Learning'' (MADBAL), an AL
method that benefits from a hierarchical approach to define a multiview data
distribution, which takes into account the different ""sample"" definitions
jointly, hence able to select the most impactful segmentation pixels with
comprehensive understanding. MADBAL also features a novel uncertainty
formulation, where AL supporting modules are included to sense the features'
maturity whose weighted influence continuously contributes to the uncertainty
detection. In this way, MADBAL makes significant performance leaps even in the
early AL stage, hence reducing the training burden significantly. It
outperforms state-of-the-art methods on Cityscapes and PASCAL VOC datasets as
verified in our extensive experiments.",5
2308.11503v1,math.NA,Multi-level Neural Networks for Accurate Solutions of Boundary-Value Problems,"The solution to partial differential equations using deep learning approaches
has shown promising results for several classes of initial and boundary-value
problems. However, their ability to surpass, particularly in terms of accuracy,
classical discretization methods such as the finite element methods, remains a
significant challenge. Deep learning methods usually struggle to reliably
decrease the error in their approximate solution. A new methodology to better
control the error for deep learning methods is presented here. The main idea
consists in computing an initial approximation to the problem using a simple
neural network and in estimating, in an iterative manner, a correction by
solving the problem for the residual error with a new network of increasing
complexity. This sequential reduction of the residual of the partial
differential equation allows one to decrease the solution error, which, in some
cases, can be reduced to machine precision. The underlying explanation is that
the method is able to capture at each level smaller scales of the solution
using a new network. Numerical examples in 1D and 2D are presented to
demonstrate the effectiveness of the proposed approach. This approach applies
not only to physics informed neural networks but to other neural network
solvers based on weak or strong formulations of the residual.",8
2308.14487v1,math.NA,Deep multi-step mixed algorithm for high dimensional non-linear PDEs and associated BSDEs,"We propose a new multistep deep learning-based algorithm for the resolution
of moderate to high dimensional nonlinear backward stochastic differential
equations (BSDEs) and their corresponding parabolic partial differential
equations (PDE). Our algorithm relies on the iterated time discretisation of
the BSDE and approximates its solution and gradient using deep neural networks
and automatic differentiation at each time step. The approximations are
obtained by sequential minimisation of local quadratic loss functions at each
time step through stochastic gradient descent. We provide an analysis of
approximation error in the case of a network architecture with weight
constraints requiring only low regularity conditions on the generator of the
BSDE. The algorithm increases accuracy from its single step parent model and
has reduced complexity when compared to similar models in the literature.",2
2308.14933v1,math.NA,A hybridizable discontinuous Galerkin method for the dual-porosity-Stokes problem,"We introduce and analyze a hybridizable discontinuous Galerkin (HDG) method
for the dual-porosity-Stokes problem. This coupled problem describes the
interaction between free flow in macrofractures/conduits, governed by the
Stokes equations, and flow in microfractures/matrix, governed by a
dual-porosity model. We prove that the HDG method is strongly conservative,
well-posed, and give an a priori error analysis showing dependence on the
problem parameters. Our theoretical findings are corroborated by numerical
examples",1
2308.14705v1,stat.ML,Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning,"Ensembling a neural network is a widely recognized approach to enhance model
performance, estimate uncertainty, and improve robustness in deep supervised
learning. However, deep ensembles often come with high computational costs and
memory demands. In addition, the efficiency of a deep ensemble is related to
diversity among the ensemble members which is challenging for large,
over-parameterized deep neural networks. Moreover, ensemble learning has not
yet seen such widespread adoption, and it remains a challenging endeavor for
self-supervised or unsupervised representation learning. Motivated by these
challenges, we present a novel self-supervised training regime that leverages
an ensemble of independent sub-networks, complemented by a new loss function
designed to encourage diversity. Our method efficiently builds a sub-model
ensemble with high diversity, leading to well-calibrated estimates of model
uncertainty, all achieved with minimal computational overhead compared to
traditional deep self-supervised ensembles. To evaluate the effectiveness of
our approach, we conducted extensive experiments across various tasks,
including in-distribution generalization, out-of-distribution detection,
dataset corruption, and semi-supervised settings. The results demonstrate that
our method significantly improves prediction reliability. Our approach not only
achieves excellent accuracy but also enhances calibration, surpassing baseline
performance across a wide range of self-supervised architectures in computer
vision, natural language processing, and genomics data.",6
2308.15363v1,cs.DB,Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation,"Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL
task. However, the absence of a systematical benchmark inhibits the development
of designing effective, efficient and economic LLM-based Text-to-SQL solutions.
To address this challenge, in this paper, we first conduct a systematical and
extensive comparison over existing prompt engineering methods, including
question representation, example selection and example organization, and with
these experimental results, we elaborates their pros and cons. Based on these
findings, we propose a new integrated solution, named DAIL-SQL, which refreshes
the Spider leaderboard with 86.6% execution accuracy and sets a new bar.
Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize
the token efficiency in prompt engineering and compare the prior studies under
this metric. Additionally, we investigate open-source LLMs in in-context
learning, and further enhance their performance with task-specific supervised
fine-tuning. Our explorations highlight open-source LLMs' potential in
Text-to-SQL, as well as the advantages and disadvantages of the task-specific
supervised fine-tuning. We hope that our work provides a deeper understanding
of Text-to-SQL with LLMs, and inspire further investigations and broad
applications.",7
2308.15256v1,eess.AS,Let There Be Sound: Reconstructing High Quality Speech from Silent Videos,"The goal of this work is to reconstruct high quality speech from lip motions
alone, a task also known as lip-to-speech. A key challenge of lip-to-speech
systems is the one-to-many mapping caused by (1) the existence of homophenes
and (2) multiple speech variations, resulting in a mispronounced and
over-smoothed speech. In this paper, we propose a novel lip-to-speech system
that significantly improves the generation quality by alleviating the
one-to-many mapping problem from multiple perspectives. Specifically, we
incorporate (1) self-supervised speech representations to disambiguate
homophenes, and (2) acoustic variance information to model diverse speech
styles. Additionally, to better solve the aforementioned problem, we employ a
flow based post-net which captures and refines the details of the generated
speech. We perform extensive experiments and demonstrate that our method
achieves the generation quality close to that of real human utterance,
outperforming existing methods in terms of speech naturalness and
intelligibility by a large margin. Synthesised samples are available at the
anonymous demo page: https://mm.kaist.ac.kr/projects/LTBS.",8
2308.15308v1,cs.LG,On-Device Learning with Binary Neural Networks,"Existing Continual Learning (CL) solutions only partially address the
constraints on power, memory and computation of the deep learning models when
deployed on low-power embedded CPUs. In this paper, we propose a CL solution
that embraces the recent advancements in CL field and the efficiency of the
Binary Neural Networks (BNN), that use 1-bit for weights and activations to
efficiently execute deep learning models. We propose a hybrid quantization of
CWR* (an effective CL approach) that considers differently forward and backward
pass in order to retain more precision during gradient update step and at the
same time minimizing the latency overhead. The choice of a binary network as
backbone is essential to meet the constraints of low power devices and, to the
best of authors' knowledge, this is the first attempt to prove on-device
learning with BNN. The experimental validation carried out confirms the
validity and the suitability of the proposed method.",6
2308.14239v1,quant-ph,Quantum Next Generation Reservoir Computing: An Efficient Quantum Algorithm for Forecasting Quantum Dynamics,"Next Generation Reservoir Computing (NG-RC) is a modern class of model-free
machine learning that enables an accurate forecasting of time series data
generated by dynamical systems. We demonstrate that NG-RC can accurately
predict full many-body quantum dynamics, instead of merely concentrating on the
dynamics of observables, which is the conventional application of reservoir
computing. In addition, we apply a technique which we refer to as skipping
ahead to predict far future states accurately without the need to extract
information about the intermediate states. However, adopting a classical NG-RC
for many-body quantum dynamics prediction is computationally prohibitive due to
the large Hilbert space of sample input data. In this work, we propose an
end-to-end quantum algorithm for many-body quantum dynamics forecasting with a
quantum computational speedup via the block-encoding technique. This proposal
presents an efficient model-free quantum scheme to forecast quantum dynamics
coherently, bypassing inductive biases incurred in a model-based approach.",5
2308.15022v1,cs.CL,Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models,"Most open-domain dialogue systems suffer from forgetting important
information, especially in a long-term conversation. Existing works usually
train the specific retriever or summarizer to obtain key information from the
past, which is time-consuming and highly depends on the quality of labeled
data. To alleviate this problem, we propose to recursively generate summaries/
memory using large language models (LLMs) to enhance long-term memory ability.
Specifically, our method first stimulates LLMs to memorize small dialogue
contexts and then recursively produce new memory using previous memory and
following contexts. Finally, the LLM can easily generate a highly consistent
response with the help of the latest memory. We evaluate our method using
ChatGPT and text-davinci-003, and the experiments on the widely-used public
dataset show that our method can generate more consistent responses in a
long-context conversation. Notably, our method is a potential solution to
enable the LLM to model the extremely long context. Code and scripts will be
released later.",8
2308.12145v1,math.NA,Modeling excitable cells with the EMI equations: spectral analysis and iterative solution strategy,"In this work, we are interested in solving large linear systems stemming from
the Extra-Membrane-Intra (EMI) model, which is employed for simulating
excitable tissues at a cellular scale. After setting the related systems of
partial differential equations (PDEs) equipped with proper boundary conditions,
we provide numerical approximation schemes for the EMI PDEs and focus on the
resulting large linear systems. We first give a relatively complete spectral
analysis using tools from the theory of Generalized Locally Toeplitz matrix
sequences. The obtained spectral information is used for designing appropriate
(preconditioned) Krylov solvers. We show, through numerical experiments, that
the presented solution strategy is robust w.r.t. problem and discretization
parameters, efficient and scalable.",1
2308.12164v1,math.NA,A robust family of exponential attractors for a linear time discretization of the Cahn-Hilliard equation with a source term,"We consider a linear implicit-explicit (IMEX) time discretization of the
Cahn-Hilliard equation with a source term, endowed with Dirichlet boundary
conditions. For every time step small enough, we build an exponential attractor
of the discrete-in-time dynamical system associated to the discretization. We
prove that, as the time step tends to 0, this attractor converges for the
symmmetric Hausdorff distance to an exponential attractor of the
continuous-in-time dynamical system associated with the PDE. We also prove that
the fractal dimension of the exponential attractor (and consequently, of the
global attractor) is bounded by a constant independent of the time step. The
results also apply to the classical Cahn-Hilliard equation with Neumann
boundary conditions.",1
2308.13506v2,cs.CL,Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level,"As research on machine translation moves to translating text beyond the
sentence level, it remains unclear how effective automatic evaluation metrics
are at scoring longer translations. In this work, we first propose a method for
creating paragraph-level data for training and meta-evaluating metrics from
existing sentence-level data. Then, we use these new datasets to benchmark
existing sentence-level metrics as well as train learned metrics at the
paragraph level. Interestingly, our experimental results demonstrate that using
sentence-level metrics to score entire paragraphs is equally as effective as
using a metric designed to work at the paragraph level. We speculate this
result can be attributed to properties of the task of reference-based
evaluation as well as limitations of our datasets with respect to capturing all
types of phenomena that occur in paragraph-level translations.",4
2308.12416v1,eess.IV,Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach,"Deep learning models have achieved state-of-the-art results in estimating
brain age, which is an important brain health biomarker, from magnetic
resonance (MR) images. However, most of these models only provide a global age
prediction, and rely on techniques, such as saliency maps to interpret their
results. These saliency maps highlight regions in the input image that were
significant for the model's predictions, but they are hard to be interpreted,
and saliency map values are not directly comparable across different samples.
In this work, we reframe the age prediction problem from MR images to an
image-to-image regression problem where we estimate the brain age for each
brain voxel in MR images. We compare voxel-wise age prediction models against
global age prediction models and their corresponding saliency maps. The results
indicate that voxel-wise age prediction models are more interpretable, since
they provide spatial information about the brain aging process, and they
benefit from being quantitative.",2
2308.14482v1,cs.CL,An Empirical Study of Consistency Regularization for End-to-End Speech-to-Text Translation,"Consistency regularization methods, such as R-Drop (Liang et al., 2021) and
CrossConST (Gao et al., 2023), have achieved impressive supervised and
zero-shot performance in the neural machine translation (NMT) field. Can we
also boost end-to-end (E2E) speech-to-text translation (ST) by leveraging
consistency regularization? In this paper, we conduct empirical studies on
intra-modal and cross-modal consistency and propose two training strategies,
SimRegCR and SimZeroCR, for E2E ST in regular and zero-shot scenarios.
Experiments on the MuST-C benchmark show that our approaches achieve
state-of-the-art (SOTA) performance in most translation directions. The
analyses prove that regularization brought by the intra-modal consistency,
instead of modality gap, is crucial for the regular E2E ST, and the cross-modal
consistency could close the modality gap and boost the zero-shot E2E ST
performance.",5
2308.14936v1,cs.CV,Auto-Prompting SAM for Mobile Friendly 3D Medical Image Segmentation,"The Segment Anything Model (SAM) has rapidly been adopted for segmenting a
wide range of natural images. However, recent studies have indicated that SAM
exhibits subpar performance on 3D medical image segmentation tasks. In addition
to the domain gaps between natural and medical images, disparities in the
spatial arrangement between 2D and 3D images, the substantial computational
burden imposed by powerful GPU servers, and the time-consuming manual prompt
generation impede the extension of SAM to a broader spectrum of medical image
segmentation applications. To address these challenges, in this work, we
introduce a novel method, AutoSAM Adapter, designed specifically for 3D
multi-organ CT-based segmentation. We employ parameter-efficient adaptation
techniques in developing an automatic prompt learning paradigm to facilitate
the transformation of the SAM model's capabilities to 3D medical image
segmentation, eliminating the need for manually generated prompts. Furthermore,
we effectively transfer the acquired knowledge of the AutoSAM Adapter to other
lightweight models specifically tailored for 3D medical image analysis,
achieving state-of-the-art (SOTA) performance on medical image segmentation
tasks. Through extensive experimental evaluation, we demonstrate the AutoSAM
Adapter as a critical foundation for effectively leveraging the emerging
ability of foundation models in 2D natural image segmentation for 3D medical
image segmentation.",3
2308.15178v1,cs.AI,Symbolic LTLf Best-Effort Synthesis,"We consider an agent acting to fulfil tasks in a nondeterministic
environment. When a strategy that fulfills the task regardless of how the
environment acts does not exist, the agent should at least avoid adopting
strategies that prevent from fulfilling its task. Best-effort synthesis
captures this intuition. In this paper, we devise and compare various symbolic
approaches for best-effort synthesis in Linear Temporal Logic on finite traces
(LTLf). These approaches are based on the same basic components, however they
change in how these components are combined, and this has a significant impact
on the performance of the approaches as confirmed by our empirical evaluations.",1
2308.11821v1,math.NA,Multi-temporal decomposition for elastoplastic ratcheting solids,"This paper presents a multi-temporal formulation for simulating elastoplastic
solids under cyclic loading. We leverage the proper generalized decomposition
(PGD) to decompose the displacements into multiple time scales, separating the
spatial and intra-cyclic dependence from the inter-cyclic variation. In
contrast with the standard incremental approach, which solves the (non-linear
and computationally intensive) mechanical balance equations at every time step,
the proposed PGD approach allows the mechanical balance equations to be solved
exclusively for the small-time intra-cyclic response, while the large-time
inter-cyclic response is described by simple scalar algebraic equations.
Numerical simulations exhibiting complex cyclic responses, including a 2D
problem and an application to a monopile foundation, demonstrate that PGD
solutions with a limited number of space-time degrees of freedom may be
obtained numerically, only requiring a few modes to accurately capture the
reference response.",1
2308.15078v1,cs.AI,LAMBO: Large Language Model Empowered Edge Intelligence,"Next-generation edge intelligence is anticipated to bring huge benefits to
various applications, e.g., offloading systems. However, traditional deep
offloading architectures face several issues, including heterogeneous
constraints, partial perception, uncertain generalization, and lack of
tractability. In this context, the integration of offloading with large
language models (LLMs) presents numerous advantages. Therefore, we propose an
LLM-Based Offloading (LAMBO) framework for mobile edge computing (MEC), which
comprises four components: (i) Input embedding (IE), which is used to represent
the information of the offloading system with constraints and prompts through
learnable vectors with high quality; (ii) Asymmetric encoderdecoder (AED)
model, which is a decision-making module with a deep encoder and a shallow
decoder. It can achieve high performance based on multi-head self-attention
schemes; (iii) Actor-critic reinforcement learning (ACRL) module, which is
employed to pre-train the whole AED for different optimization tasks under
corresponding prompts; and (iv) Active learning from expert feedback (ALEF),
which can be used to finetune the decoder part of the AED while adapting to
dynamic environmental changes. Our simulation results corroborate the
advantages of the proposed LAMBO framework.",7
2308.15457v1,cs.LG,From SMOTE to Mixup for Deep Imbalanced Classification,"Given imbalanced data, it is hard to train a good classifier using deep
learning because of the poor generalization of minority classes. Traditionally,
the well-known synthetic minority oversampling technique (SMOTE) for data
augmentation, a data mining approach for imbalanced learning, has been used to
improve this generalization. However, it is unclear whether SMOTE also benefits
deep learning. In this work, we study why the original SMOTE is insufficient
for deep learning, and enhance SMOTE using soft labels. Connecting the
resulting soft SMOTE with Mixup, a modern data augmentation technique, leads to
a unified framework that puts traditional and modern data augmentation
techniques under the same umbrella. A careful study within this framework shows
that Mixup improves generalization by implicitly achieving uneven margins
between majority and minority classes. We then propose a novel margin-aware
Mixup technique that more explicitly achieves uneven margins. Extensive
experimental results demonstrate that our proposed technique yields
state-of-the-art performance on deep imbalanced classification while achieving
superior performance on extremely imbalanced data. The code is open-sourced in
our developed package https://github.com/ntucllab/imbalanced-DL to foster
future research in this direction.",3
2308.12907v1,math.NA,New time domain decomposition methods for parabolic control problems I: Dirichlet-Neumann and Neumann-Dirichlet algorithms,"We present new Dirichlet-Neumann and Neumann-Dirichlet algorithms with a time
domain decomposition applied to unconstrained parabolic optimal control
problems. After a spatial semi-discretization, we use the Lagrange multiplier
approach to derive a coupled forward-backward optimality system, which can then
be solved using a time domain decomposition. Due to the forward-backward
structure of the optimality system, three variants can be found for the
Dirichlet-Neumann and Neumann-Dirichlet algorithms. We analyze their
convergence behavior and determine the optimal relaxation parameter for each
algorithm. Our analysis reveals that the most natural algorithms are actually
only good smoothers, and there are better choices which lead to efficient
solvers. We illustrate our analysis with numerical experiments.",1
2308.13754v1,cs.SE,ZC3: Zero-Shot Cross-Language Code Clone Detection,"Developers introduce code clones to improve programming productivity. Many
existing studies have achieved impressive performance in monolingual code clone
detection. However, during software development, more and more developers write
semantically equivalent programs with different languages to support different
platforms and help developers translate projects from one language to another.
Considering that collecting cross-language parallel data, especially for
low-resource languages, is expensive and time-consuming, how designing an
effective cross-language model that does not rely on any parallel data is a
significant problem. In this paper, we propose a novel method named ZC3 for
Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive
snippet prediction to form an isomorphic representation space among different
programming languages. Based on this, ZC3 exploits domain-aware learning and
cycle consistency learning to further constrain the model to generate
representations that are aligned among different languages meanwhile are
diacritical for different types of clones. To evaluate our approach, we conduct
extensive experiments on four representative cross-language clone detection
datasets. Experimental results show that ZC3 outperforms the state-of-the-art
baselines by 67.12%, 51.39%, 14.85%, and 53.01% on the MAP score, respectively.
We further investigate the representational distribution of different languages
and discuss the effectiveness of our method.",8
2308.12312v1,physics.comp-ph,Physics informed Neural Networks applied to the description of wave-particle resonance in kinetic simulations of fusion plasmas,"The Vlasov-Poisson system is employed in its reduced form version (1D1V) as a
test bed for the applicability of Physics Informed Neural Network (PINN) to the
wave-particle resonance. Two examples are explored: the Landau damping and the
bump-on-tail instability. PINN is first tested as a compression method for the
solution of the Vlasov-Poisson system and compared to the standard neural
networks. Second, the application of PINN to solving the Vlasov-Poisson system
is also presented with the special emphasis on the integral part, which
motivates the implementation of a PINN variant, called Integrable PINN
(I-PINN), based on the automatic-differentiation to solve the partial
differential equation and on the automatic-integration to solve the integral
equation.",4
2308.15464v1,cs.LG,A Comparative Study of Loss Functions: Traffic Predictions in Regular and Congestion Scenarios,"Spatiotemporal graph neural networks have achieved state-of-the-art
performance in traffic forecasting. However, they often struggle to forecast
congestion accurately due to the limitations of traditional loss functions.
While accurate forecasting of regular traffic conditions is crucial, a reliable
AI system must also accurately forecast congestion scenarios to maintain safe
and efficient transportation. In this paper, we explore various loss functions
inspired by heavy tail analysis and imbalanced classification problems to
address this issue. We evaluate the efficacy of these loss functions in
forecasting traffic speed, with an emphasis on congestion scenarios. Through
extensive experiments on real-world traffic datasets, we discovered that when
optimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function stands
out as the most effective. When optimizing Mean Squared Error (MSE), Gumbel
Loss proves to be the superior choice. These choices effectively forecast
traffic congestion events without compromising the accuracy of regular traffic
speed forecasts. This research enhances deep learning models' capabilities in
forecasting sudden speed changes due to congestion and underscores the need for
more research in this direction. By elevating the accuracy of congestion
forecasting, we advocate for AI systems that are reliable, secure, and
resilient in practical traffic management scenarios.",5
2308.15072v1,cs.LG,Advancing Adversarial Robustness Through Adversarial Logit Update,"Deep Neural Networks are susceptible to adversarial perturbations.
Adversarial training and adversarial purification are among the most widely
recognized defense strategies. Although these methods have different underlying
logic, both rely on absolute logit values to generate label predictions. In
this study, we theoretically analyze the logit difference around successful
adversarial attacks from a theoretical point of view and propose a new
principle, namely Adversarial Logit Update (ALU), to infer adversarial sample's
labels. Based on ALU, we introduce a new classification paradigm that utilizes
pre- and post-purification logit differences for model's adversarial robustness
boost. Without requiring adversarial or additional data for model training, our
clean data synthesis model can be easily applied to various pre-trained models
for both adversarial sample detection and ALU-based data classification.
Extensive experiments on both CIFAR-10, CIFAR-100, and tiny-ImageNet datasets
show that even with simple components, the proposed solution achieves superior
robustness performance compared to state-of-the-art methods against a wide
range of adversarial attacks. Our python implementation is submitted in our
Supplementary document and will be published upon the paper's acceptance.",1
2308.15230v1,cs.IR,Providing Previously Unseen Users Fair Recommendations Using Variational Autoencoders,"An emerging definition of fairness in machine learning requires that models
are oblivious to demographic user information, e.g., a user's gender or age
should not influence the model. Personalized recommender systems are
particularly prone to violating this definition through their explicit user
focus and user modelling. Explicit user modelling is also an aspect that makes
many recommender systems incapable of providing hitherto unseen users with
recommendations. We propose novel approaches for mitigating discrimination in
Variational Autoencoder-based recommender systems by limiting the encoding of
demographic information. The approaches are capable of, and evaluated on,
providing users that are not represented in the training data with fair
recommendations.",1
2308.14077v1,cs.FL,An Analysis of On-the-fly Determinization of Finite-state Automata,"In this paper we establish an abstraction of on-the-fly determinization of
finite-state automata using transition monoids and demonstrate how it can be
applied to bound the asymptotics. We present algebraic and combinatorial
properties that are sufficient for a polynomial state complexity of the
deterministic automaton constructed on-the-fly. A special case of our findings
is that automata with many non-deterministic transitions almost always admit a
determinization of polynomial complexity. Furthermore, we extend our ideas to
weighted finite-state automata.",1
2308.15405v1,cs.LG,Robust Long-Tailed Learning via Label-Aware Bounded CVaR,"Data in the real-world classification problems are always imbalanced or
long-tailed, wherein the majority classes have the most of the samples that
dominate the model training. In such setting, the naive model tends to have
poor performance on the minority classes. Previously, a variety of loss
modifications have been proposed to address the long-tailed leaning problem,
while these methods either treat the samples in the same class
indiscriminatingly or lack a theoretical guarantee. In this paper, we propose
two novel approaches based on CVaR (Conditional Value at Risk) to improve the
performance of long-tailed learning with a solid theoretical ground.
Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss
to overcome the pessimistic result of the original CVaR, and further design the
optimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we
additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to
stabilize the optimization process, where we also offer the theoretical
support. Extensive experiments on real-world datasets with long-tailed label
distributions verify the superiority of our proposed methods.",2
