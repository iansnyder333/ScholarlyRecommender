<!DOCTYPE html>
    <html>
    <body>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Evaluation and Analysis of Hallucination in Large Vision-Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Junyang Wang, Yiyang Zhou, Guohai Xu, Pengcheng Shi, Chenlin Zhao, Haiyang Xu, Qinghao Ye, Ming Yan, Ji Zhang, Jihua Zhu, Jitao Sang, Haoyu Tang</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15126v1</span> | 
        <span class="category">cs.LG</span> | 
        <span class="published">Published on 08-29-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Large Vision-Language Models (LVLMs) have recently achieved remarkable
success. However, LVLMs are still plagued by the hallucination problem, which
limits the practicality in many scenarios. Hallucination refers to the
information of LVLMs' responses that does not exist in the visual input, which
poses potential risks of substantial consequences. There has been limited work
studying hallucination evaluation in LVLMs. In this paper, we propose
Hallucination Evaluation based on Large Language Mod...
    </div>
    <a href="http://arxiv.org/pdf/2308.15126v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Xin Zhang, Dong Zhang, Shimin Li, Yaqian Zhou, Xipeng Qiu</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.16692v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-31-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Current speech large language models build upon discrete speech
representations, which can be categorized into semantic tokens and acoustic
tokens. However, existing speech tokens are not specifically designed for
speech language modeling. To assess the suitability of speech tokens for
building speech language models, we established the first benchmark,
SLMTokBench. Our results indicate that neither semantic nor acoustic tokens are
ideal for this purpose. Therefore, we propose SpeechTokenizer, a...
    </div>
    <a href="http://arxiv.org/pdf/2308.16692v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">LLaSM: Large Language and Speech Model</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang, Yemin Shi</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15930v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Multi-modal large language models have garnered significant interest
recently. Though, most of the works focus on vision-language multi-modal models
providing strong capabilities in following vision-and-language instructions.
However, we claim that speech is also an important modality through which
humans interact with the world. Hence, it is crucial for a general-purpose
assistant to be able to follow multi-modal speech-and-language instructions. In
this work, we propose Large Language and Spee...
    </div>
    <a href="http://arxiv.org/pdf/2308.15930v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Large Language Models as Data Preprocessors</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Haochen Zhang, Yuyang Dong, Chuan Xiao, Masafumi Oyamada</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.16361v1</span> | 
        <span class="category">cs.AI</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's
LLaMA variants, have marked a significant advancement in artificial
intelligence. Trained on vast amounts of text data, LLMs are capable of
understanding and generating human-like text across a diverse range of topics.
This study expands on the applications of LLMs, exploring their potential in
data preprocessing, a critical stage in data mining and analytics applications.
We delve into the applicability of state-of-the-art...
    </div>
    <a href="http://arxiv.org/pdf/2308.16361v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Qingyue Wang, Liang Ding, Yanan Cao, Zhiliang Tian, Shi Wang, Dacheng Tao, Li Guo</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15022v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-29-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Most open-domain dialogue systems suffer from forgetting important
information, especially in a long-term conversation. Existing works usually
train the specific retriever or summarizer to obtain key information from the
past, which is time-consuming and highly depends on the quality of labeled
data. To alleviate this problem, we propose to recursively generate summaries/
memory using large language models (LLMs) to enhance long-term memory ability.
Specifically, our method first stimulates LLMs...
    </div>
    <a href="http://arxiv.org/pdf/2308.15022v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
     </body>
    </html>