<!DOCTYPE html>
    <html>
    <body>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Cognitive Effects in Large Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Jonathan Shaki, Sarit Kraus, Michael Wooldridge</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.14337v1</span> | 
        <span class="category">cs.AI</span> | 
        <span class="published">Published on 08-28-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Large Language Models (LLMs) such as ChatGPT have received enormous attention
over the past year and are now used by hundreds of millions of people every
day. The rapid adoption of this technology naturally raises questions about the
possible biases such models might exhibit. In this work, we tested one of these
models (GPT-3) on a range of cognitive effects, which are systematic patterns
that are usually found in human cognitive tasks. We found that LLMs are indeed
prone to several human cognit...
    </div>
    <a href="http://arxiv.org/pdf/2308.14337v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Gender bias and stereotypes in Large Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Hadas Kotek, Rikker Dockum, David Q. Sun</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.14921v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-28-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Large Language Models (LLMs) have made substantial progress in the past
several months, shattering state-of-the-art benchmarks in many domains. This
paper investigates LLMs' behavior with respect to gender stereotypes, a known
issue for prior models. We use a simple paradigm to test the presence of gender
bias, building on but differing from WinoBias, a commonly used gender bias
dataset, which is likely to be included in the training data of current LLMs.
We test four recently published LLMs and...
    </div>
    <a href="http://arxiv.org/pdf/2308.14921v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Evaluation and Analysis of Hallucination in Large Vision-Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Junyang Wang, Yiyang Zhou, Guohai Xu, Pengcheng Shi, Chenlin Zhao, Haiyang Xu, Qinghao Ye, Ming Yan, Ji Zhang, Jihua Zhu, Jitao Sang, Haoyu Tang</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15126v1</span> | 
        <span class="category">cs.LG</span> | 
        <span class="published">Published on 08-29-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Large Vision-Language Models (LVLMs) have recently achieved remarkable
success. However, LVLMs are still plagued by the hallucination problem, which
limits the practicality in many scenarios. Hallucination refers to the
information of LVLMs' responses that does not exist in the visual input, which
poses potential risks of substantial consequences. There has been limited work
studying hallucination evaluation in LVLMs. In this paper, we propose
Hallucination Evaluation based on Large Language Mod...
    </div>
    <a href="http://arxiv.org/pdf/2308.15126v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Large Language Models as Data Preprocessors</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Haochen Zhang, Yuyang Dong, Chuan Xiao, Masafumi Oyamada</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.16361v1</span> | 
        <span class="category">cs.AI</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's
LLaMA variants, have marked a significant advancement in artificial
intelligence. Trained on vast amounts of text data, LLMs are capable of
understanding and generating human-like text across a diverse range of topics.
This study expands on the applications of LLMs, exploring their potential in
data preprocessing, a critical stage in data mining and analytics applications.
We delve into the applicability of state-of-the-art...
    </div>
    <a href="http://arxiv.org/pdf/2308.16361v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">LLaSM: Large Language and Speech Model</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang, Yemin Shi</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15930v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Multi-modal large language models have garnered significant interest
recently. Though, most of the works focus on vision-language multi-modal models
providing strong capabilities in following vision-and-language instructions.
However, we claim that speech is also an important modality through which
humans interact with the world. Hence, it is crucial for a general-purpose
assistant to be able to follow multi-modal speech-and-language instructions. In
this work, we propose Large Language and Spee...
    </div>
    <a href="http://arxiv.org/pdf/2308.15930v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
     </body>
    </html>