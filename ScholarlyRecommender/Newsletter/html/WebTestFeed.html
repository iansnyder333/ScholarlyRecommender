<!DOCTYPE html>
    <html>
    <body>
    
<h2 class="title-main" style='font-family: "Open Sans", sans-serif; color: #34495e;font-family: Arial, sans-serif;
    font-size: 28px;
    letter-spacing: 0.05em;
    
    color: #2C3E50;
    margin-bottom: 10px;'>Decoding the Future of AI: Ethical Dilemmas, Embedding Logic, and Emotion Analytics in Conversational Techâ€”A Curated Selection of Cutting-Edge Research</h2>
<p style='font-family: "Open Sans", sans-serif; color: #2c3e50; font-size: 18px;  margin-bottom: 20px; line-height: 1.6;'>
    Dear Reader,
    </p>
<p style='font-family: "Open Sans", sans-serif; color: #2c3e50; font-size: 18px;  margin-bottom: 20px; line-height: 1.6;'>
        This edition aims to immerse you in the nuanced fabric of Large Language Models, spanning topics from ethical concerns in moderation and gender biases to highly technical advancements like embedding logic programming into Python's deep-learning ecosystem. Expect in-depth analyses and pioneering solutions that push the boundaries of conventional wisdom, handpicked to empower your specialized interest in these paradigms.
</p>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">LLaSM: Large Language and Speech Model</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang, Yemin Shi</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15930v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Multi-modal large language models have garnered significant interest
recently. Though, most of the works focus on vision-language multi-modal models
providing strong capabilities in following vision-and-language instructions.
However, we claim that speech is also an important modality through which
humans interact with the world. Hence, it is crucial for a general-purpose
assistant to be able to follow multi-modal speech-and-language instructions. In
this work, we propose Large Language and Spee...
    </div>
    <a href="http://arxiv.org/pdf/2308.15930v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Tianyu Wang, Yifan Li, Haitao Lin, Xiangyang Xue, Yanwei Fu</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15962v1</span> | 
        <span class="category">cs.RO</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Enabling robots to understand language instructions and react accordingly to
visual perception has been a long-standing goal in the robotics research
community. Achieving this goal requires cutting-edge advances in natural
language processing, computer vision, and robotics engineering. Thus, this
paper mainly investigates the potential of integrating the most recent Large
Language Models (LLMs) and existing visual grounding and robotic grasping
system to enhance the effectiveness of the human-ro...
    </div>
    <a href="http://arxiv.org/pdf/2308.15962v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Hritik Bansal, John Dang, Aditya Grover</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15812v1</span> | 
        <span class="category">cs.LG</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        Aligning large language models (LLMs) with human values and intents
critically involves the use of human or AI feedback. While dense feedback
annotations are expensive to acquire and integrate, sparse feedback presents a
structural design choice between ratings (e.g., score Response A on a scale of
1-7) and rankings (e.g., is Response A better than Response B?). In this work,
we analyze the effect of this design choice for the alignment and evaluation of
LLMs. We uncover an inconsistency problem...
    </div>
    <a href="http://arxiv.org/pdf/2308.15812v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">WUDI: A Human Involved Self-Adaptive Framework to Prevent Childhood Obesity in Internet of Things Environment</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Euijong Lee, Jaemin Jung, Gee-Myung Moon, Seong-Whan Lee, Ji-Hoon Jeong</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.15944v1</span> | 
        <span class="category">cs.SE</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        The Internet of Things (IoT) connects people, devices, and information
resources, in various domains to improve efficiency. The healthcare domain has
been transformed by the integration of the IoT, leading to the development of
digital healthcare solutions such as health monitoring, emergency detection,
and remote operation. This integration has led to an increase in the health
data collected from a variety of IoT sources. Consequently, advanced
technologies are required to analyze health data, ...
    </div>
    <a href="http://arxiv.org/pdf/2308.15944v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
    
    <div class="feed-item" style="border: 1px solid #ccc;
    padding: 15px;
    margin: 15px;
    border-radius: 8px;">
    <h2 class="title" style=" font-size: 24px;
    font-weight: bold;
    margin-bottom: 5px; color: #000000;">LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models</h2>
    <h4 class="author" style="font-size: 14px;
    font-weight: bold;
    margin-bottom: 10px; color:#000000;">Chi Han, Qifan Wang, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang</h4>
    <div class="metadata" style="font-size: 14px;
    color: #000000;
    margin-bottom: 10px;">
        <span class="id">Entry Id: 2308.16137v1</span> | 
        <span class="category">cs.CL</span> | 
        <span class="published">Published on 08-30-2023</span>
    </div>
    <div class="abstract" style="font-size: 16px;
    margin-bottom: 10px; color: #000000;">
        In recent years, there have been remarkable advancements in the performance
of Transformer-based Large Language Models (LLMs) across various domains. As
these LLMs are deployed for increasingly complex tasks, they often face the
needs to conduct longer reasoning processes or understanding larger contexts.
In these situations, the length generalization failure of LLMs on long
sequences become more prominent. Most pre-training schemes truncate training
sequences to a fixed length (such as 2048 for...
    </div>
    <a href="http://arxiv.org/pdf/2308.16137v1" target="_blank" style="display: inline-block;
    background-color: #007BFF;
    color: white;
    padding: 8px 16px;
    border-radius: 4px;
    text-decoration: none;">Read More</a>
    </div>
     </body>
    </html>